{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Necessary installations and Imports"
      ],
      "metadata": {
        "id": "XiJO31YACbsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install libomp-dev"
      ],
      "metadata": {
        "id": "rFdUlRC0n-CJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAmqk7rmwVq8"
      },
      "outputs": [],
      "source": [
        "!pip install -q git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q git+https://github.com/gmihaila/ml_things.git\n",
        "!pip install sentence-transformers\n",
        "!pip install datasets\n",
        "!pip install faiss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import random\n",
        "import os\n",
        "import math\n",
        "import torch\n",
        "import warnings\n",
        "from tqdm.notebook import tqdm\n",
        "from ml_things import plot_dict, fix_text\n",
        "from transformers import *\n",
        "from sentence_transformers import util\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "import faiss\n",
        "\n",
        "set_seed(1)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "gAzzUSg-wkre"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROOTPATH = '/content/drive/MyDrive/NlpProject/'"
      ],
      "metadata": {
        "id": "0hL-wF7acS3f"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ogp-O6bXLHF",
        "outputId": "7ffbcd0a-0b6f-490a-f40e-a2bd0d3f59c1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HSRijZmUz_p4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb26823b-aedd-49a2-df8f-24bd05c7d1e4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading the data and making the appropriate text file"
      ],
      "metadata": {
        "id": "bWBKucznCquB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_train(mode = 'mesra', numberOfTrainData = 100):\n",
        "  lines = []\n",
        "  with open(ROOTPATH + 'all_qazals_mesra.txt') as f:\n",
        "    lines = [ x.strip() for x in f.readlines()]\n",
        "\n",
        "  texts = []\n",
        "  if mode=='beyt':\n",
        "    for i in range(1,len(lines),2):\n",
        "      texts.append(lines[i-1]+'.'+lines[i])\n",
        "  elif mode=='mesra':\n",
        "    texts = lines\n",
        "\n",
        "\n",
        "  all_texts = '\\n'.join(texts[:min(len(lines),numberOfTrainData)])\n",
        "\n",
        "  io.open(file= ROOTPATH + 'train.txt', mode='w', encoding='utf-8').write(all_texts)\n",
        "  return texts"
      ],
      "metadata": {
        "id": "oJQJGRUyznWV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = create_train(mode = 'mesra', numberOfTrainData = 329707)"
      ],
      "metadata": {
        "id": "DyV1nVVuazPi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fine tuning the model"
      ],
      "metadata": {
        "id": "5p6B0avlDJ7O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Helper fuctions and classes"
      ],
      "metadata": {
        "id": "pOvfWB95C4g_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelDataArguments(object):\n",
        "  def __init__(self, train_data_file=None, \n",
        "               line_by_line=False, mlm=False, mlm_probability=0.15, \n",
        "               whole_word_mask=False, max_span_length=5,\n",
        "               block_size=-1, tokenizer_name=None, \n",
        "               model_name_or_path=None):\n",
        "    \n",
        "    self.train_data_file = train_data_file\n",
        "    self.line_by_line = line_by_line\n",
        "    self.mlm = mlm\n",
        "    self.whole_word_mask = whole_word_mask\n",
        "    self.mlm_probability = mlm_probability\n",
        "    self.max_span_length = max_span_length\n",
        "    self.block_size = block_size\n",
        "    self.tokenizer_name = tokenizer_name\n",
        "    self.model_name_or_path = model_name_or_path\n",
        "    return\n",
        "\n",
        "\n",
        "def get_model_config(args: ModelDataArguments):\n",
        "  model_config = AutoConfig.from_pretrained(args.model_name_or_path)\n",
        "  return model_config\n",
        "\n",
        "\n",
        "def get_tokenizer(args: ModelDataArguments):\n",
        "  if args.tokenizer_name:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(args.tokenizer_name)\n",
        "\n",
        "  # Dont go beyond tokenizer maximum length.\n",
        "  args.block_size = min(args.block_size, tokenizer.model_max_length)\n",
        "\n",
        "  return tokenizer\n",
        "  \n",
        "\n",
        "def get_model(args: ModelDataArguments, model_config):\n",
        "  if type(model_config) in MODEL_FOR_MASKED_LM_MAPPING.keys():\n",
        "    return AutoModelForMaskedLM.from_pretrained(args.model_name_or_path, from_tf=bool(\".ckpt\" in args.model_name_or_path), config=model_config)\n",
        "\n",
        "\n",
        "def get_dataset(args: ModelDataArguments, tokenizer: PreTrainedTokenizer, evaluate: bool=False):\n",
        "  file_path = args.train_data_file\n",
        "  if args.line_by_line:\n",
        "    return LineByLineTextDataset(tokenizer=tokenizer, file_path=file_path,block_size=args.block_size)\n",
        "\n",
        "  else:\n",
        "    return TextDataset(tokenizer=tokenizer, file_path=file_path,block_size=args.block_size)\n",
        "\n",
        "def get_collator(args: ModelDataArguments, model_config: PretrainedConfig,tokenizer: PreTrainedTokenizer):\n",
        "  return DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=args.mlm, mlm_probability=args.mlm_probability,)\n"
      ],
      "metadata": {
        "id": "SE9sTfpUwu_n"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Defining the arguments"
      ],
      "metadata": {
        "id": "76LKNneHDR-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_data_args = ModelDataArguments(\n",
        "                                    train_data_file= ROOTPATH + 'train.txt', \n",
        "                                    line_by_line=True, \n",
        "                                    mlm=True,\n",
        "                                    whole_word_mask=True,\n",
        "                                    mlm_probability=0.15,\n",
        "                                    max_span_length=5,\n",
        "                                    block_size=50, \n",
        "                                    tokenizer_name='SajjadAyoubi/distil-bigbird-fa-zwnj', \n",
        "                                    model_name_or_path=\"SajjadAyoubi/distil-bigbird-fa-zwnj\", \n",
        "                                    )\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "                          output_dir=ROOTPATH + 'pretrain_persianbigbird',\n",
        "                          overwrite_output_dir=True,\n",
        "                          do_train=True, \n",
        "                          per_device_train_batch_size=10,\n",
        "                          prediction_loss_only=True,\n",
        "                          learning_rate = 5e-5,\n",
        "                          weight_decay=0,\n",
        "                          adam_epsilon = 1e-8,\n",
        "                          max_grad_norm = 1.0,\n",
        "                          num_train_epochs = 2,\n",
        "                          save_steps = -1,\n",
        "                          )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kwaGCZ2x51i",
        "outputId": "9a00aed1-d8ac-48d2-8f17-2723ea5f1878"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Loading the model and the tokenizer"
      ],
      "metadata": {
        "id": "VcOovJZeDZRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Loading model configuration...')\n",
        "config = get_model_config(model_data_args)\n",
        "\n",
        "print('Loading model`s tokenizer...')\n",
        "tokenizer = get_tokenizer(model_data_args)\n",
        "\n",
        "print('Loading actual model...')\n",
        "model = get_model(model_data_args, config)\n",
        "\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "metadata": {
        "id": "JOnkI_EXykkU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc564897-b4a4-4d26-e776-195b438a1d4e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model configuration...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--SajjadAyoubi--distil-bigbird-fa-zwnj/snapshots/98fd06440980957e6428dc823e16d56593fb805c/config.json\n",
            "Model config BigBirdConfig {\n",
            "  \"_name_or_path\": \"SajjadAyoubi/distil-bigbird-fa-zwnj\",\n",
            "  \"architectures\": [\n",
            "    \"BigBirdForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"attention_type\": \"block_sparse\",\n",
            "  \"block_size\": 32,\n",
            "  \"bos_token_id\": null,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 4096,\n",
            "  \"model_type\": \"big_bird\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"num_random_blocks\": 3,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"rescale_embeddings\": false,\n",
            "  \"sep_token_id\": 3,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.22.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bias\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 42000\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model`s tokenizer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--SajjadAyoubi--distil-bigbird-fa-zwnj/snapshots/98fd06440980957e6428dc823e16d56593fb805c/vocab.txt\n",
            "loading file tokenizer.json from cache at None\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--SajjadAyoubi--distil-bigbird-fa-zwnj/snapshots/98fd06440980957e6428dc823e16d56593fb805c/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--SajjadAyoubi--distil-bigbird-fa-zwnj/snapshots/98fd06440980957e6428dc823e16d56593fb805c/tokenizer_config.json\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--SajjadAyoubi--distil-bigbird-fa-zwnj/snapshots/98fd06440980957e6428dc823e16d56593fb805c/pytorch_model.bin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading actual model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint weights were used when initializing BigBirdForMaskedLM.\n",
            "\n",
            "Some weights of BigBirdForMaskedLM were not initialized from the model checkpoint at SajjadAyoubi/distil-bigbird-fa-zwnj and are newly initialized: ['bert.pooler.weight', 'bert.pooler.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(42000, 768, padding_idx=0)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating train dataset"
      ],
      "metadata": {
        "id": "0mun4ailDgzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Creating train dataset...')\n",
        "train_dataset = get_dataset(model_data_args, tokenizer=tokenizer)\n",
        "data_collator = get_collator(model_data_args, config, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "403SKw9tyo8N",
        "outputId": "ca765e4d-f908-4a1d-a2b6-afdc240e398b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:125: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  FutureWarning,\n",
            "Creating features from dataset file at /content/drive/MyDrive/NlpProject/train.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating train dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "adeSBp3bDzB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mode = 'test'\n",
        "if mode == 'train':\n",
        "  print('Loading `trainer`...')\n",
        "  trainer = Trainer(model=model,\n",
        "                    args=training_args,\n",
        "                    data_collator=data_collator,\n",
        "                    train_dataset=train_dataset)\n",
        "\n",
        "  if training_args.do_train:\n",
        "    print('Start training...')\n",
        "    model_path = (model_data_args.model_name_or_path \n",
        "                  if model_data_args.model_name_or_path is not None and \n",
        "                  os.path.isdir(model_data_args.model_name_or_path) \n",
        "                  else None\n",
        "                  )\n",
        "    trainer.train(model_path=model_path)\n",
        "    trainer.save_model()\n",
        "else:\n",
        "  model.load_state_dict(torch.load(ROOTPATH + \"pretrain_persianbigbird/pytorch_model.bin\", map_location=torch.device('cuda')))"
      ],
      "metadata": {
        "id": "sxrHR5Jhyu0T"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(texts)"
      ],
      "metadata": {
        "id": "jfmanE8yGFaC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be66a6d1-f1c3-45e6-f3c2-c89e447bdbe4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "329707"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TESTING THE CODE"
      ],
      "metadata": {
        "id": "WNjqzDCNyTgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "def knn_score(train_set, test_set, n_neighbours=1):\n",
        "    \"\"\"\n",
        "    Calculates the KNN distance\n",
        "    \"\"\"\n",
        "    train_set=train_set.detach().cpu().numpy()\n",
        "    test_set=test_set.detach().cpu().numpy()\n",
        "    index = faiss.IndexFlatL2(train_set.shape[1])\n",
        "    index.add(train_set)\n",
        "    D, idx_ = index.search(test_set, n_neighbours)\n",
        "    return idx_\n",
        "    \n",
        "def input_to_feature(input_,model):\n",
        "    text_preprocessed = input_\n",
        "    encoded = tokenizer.batch_encode_plus([text_preprocessed],max_length=50, padding='max_length', truncation=True)\n",
        "    encoded = {key:torch.LongTensor(value) for key, value in encoded.items()}\n",
        "    encoded['input_ids']=encoded['input_ids'].cuda()\n",
        "    encoded['token_type_ids']=encoded['token_type_ids'].cuda()\n",
        "    encoded['attention_mask']=encoded['attention_mask'].cuda()\n",
        "    with torch.no_grad(): \n",
        "            outputs = model(**encoded)\n",
        "    feature_outputs = outputs[0].mean(1)\n",
        "    return feature_outputs\n",
        "\n",
        "\n",
        "\n",
        "def training_set_feature_bank(model,Data):\n",
        "        \n",
        "    feature_bank=[]\n",
        " \n",
        "    batch_size = 10  \n",
        "    for idx in range(0, len(Data ), batch_size):\n",
        "        batch = Data [idx : min(len( Data), idx+batch_size)]\n",
        "        \n",
        "        # encoded = tokenizer(batch)\n",
        "        \n",
        "        encoded = tokenizer(batch,max_length=50, padding='max_length', truncation=True)\n",
        "    \n",
        "        encoded = {key:torch.LongTensor(value) for key, value in encoded.items()}\n",
        "        encoded['input_ids']=encoded['input_ids'].cuda()\n",
        "        # encoded['token_type_ids']=encoded['token_type_ids'].cuda()\n",
        "        encoded['attention_mask']=encoded['attention_mask'].cuda()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            \n",
        "            outputs = model(**encoded)\n",
        "            \n",
        "            feature_bank.append(outputs[0].mean(1))\n",
        "\n",
        "    feature_bank_t=torch.cat(feature_bank)\n",
        "    return feature_bank_t"
      ],
      "metadata": {
        "id": "P0dWiSjSPXY4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = random.sample(texts, 15000)\n",
        "queries = texts[20000:20025]"
      ],
      "metadata": {
        "id": "14r2Lf2XPtHt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "feature_bank = training_set_feature_bank(model.cuda(), docs)\n",
        "test_feature_bank = training_set_feature_bank(model, queries)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UytqpW3IPXUS",
        "outputId": "507cf147-772b-446d-da42-93a06dc6aa50"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Attention type 'block_sparse' is not possible if sequence_length: 50 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 352 with config.block_size = 32, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "def find_most_similar(_test_sentences_embedding, _train_sentences_embedding, _number_of_neighbors):\n",
        "  knn = NearestNeighbors(n_neighbors=_number_of_neighbors)\n",
        "  knn.fit(_train_sentences_embedding)\n",
        "  most_similar = knn.kneighbors(_test_sentences_embedding) \n",
        "  return most_similar"
      ],
      "metadata": {
        "id": "cxA92iilPXP-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "most_similar = find_most_similar(test_feature_bank.cpu(), feature_bank.cpu(), 10)"
      ],
      "metadata": {
        "id": "q-yqz8edPXL1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for main_sent_index, main_sent in enumerate(most_similar[1]):\n",
        "  print(\"\\n مصرع اصلی شماره \" + str(main_sent_index) + \":‌ \" + queries[main_sent_index])\n",
        "  for close_sent_index, close_sent in enumerate(main_sent):\n",
        "    print(str(close_sent_index) + \" : \" + texts[close_sent])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GShr8_mKPXHh",
        "outputId": "eece4506-1b44-4f6b-f52b-9b2b26631e09"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " مصرع اصلی شماره 0:‌ که نه امشب آن سماعست که دف خلاص یابد\n",
            "0 : دیدار دوستان که ببینند مرهمست\n",
            "1 : دوشم آن سنگ دل پریشان داشت\n",
            "2 : هر کجا هست خدایا به سلامت دارش\n",
            "3 : چه نصیبت ز بلبل سحرست\n",
            "4 : چه عذر بخت خود گویم که آن عیار شهرآشوب\n",
            "5 : دردیست در دلم که ز دیوار بگذرد\n",
            "6 : در پس آینه طوطی صفتم داشته‌اند\n",
            "7 : باز ظفر به دست و شکاری نمی‌کنی\n",
            "8 : بالله کز آفتاب فلک خوبتر شوی\n",
            "9 : عجب از دیده گریان منت می‌آید\n",
            "\n",
            " مصرع اصلی شماره 1:‌ به طپانچه‌ای و بربط برهد به گوشمالی\n",
            "0 : از جرعه تو خاک زمین در و لعل یافت\n",
            "1 : مرا به عشق تو اندیشه از ملامت نیست\n",
            "2 : عقلم اندر زمان نصیحت کرد\n",
            "3 : ترسم این نکته به تحقیق ندانی دانست\n",
            "4 : ز فکر آنان که در تدبیر درمانند در مانند\n",
            "5 : بیا که با سر زلفت قرار خواهم کرد\n",
            "6 : بی روی چو ماه آن نگارین\n",
            "7 : صد بار توبه کردم و دیگر نمی‌کنم\n",
            "8 : هزار یوسف مصری فتاده در چه ماست\n",
            "9 : گر دوست می‌آید برم یا تیغ دشمن بر سرم\n",
            "\n",
            " مصرع اصلی شماره 2:‌ دگر آفتاب رویت منمای آسمان را\n",
            "0 : که همه عمر دعاگوی و هوادار تو نیست\n",
            "1 : جام مرصع تو بدین در شاهوار\n",
            "2 : در خرقه زن آتش که خم ابروی ساقی\n",
            "3 : که بندگان بنی سعد خوان یغما را\n",
            "4 : هر نافه که در دست نسیم سحر افتاد\n",
            "5 : بوی بهبود ز اوضاع جهان می‌شنوم\n",
            "6 : عکس خوی بر عارضش بین کآفتاب گرم رو\n",
            "7 : زبانت درکش ای حافظ زمانی\n",
            "8 : مراد خاطر ما مشکلست و مشکل نیست\n",
            "9 : الا گرش برانی علت جز این نباشد\n",
            "\n",
            " مصرع اصلی شماره 3:‌ که قمر ز شرمساری بشکست چون هلالی\n",
            "0 : از سر زلف عروسان چمن دست بدارد\n",
            "1 : پرده برانداختی کار به اتمام رفت\n",
            "2 : روز قیامت زنم خیمه به پهلوی دوست\n",
            "3 : آن که از دست ملامت به فغان می‌آید\n",
            "4 : با جان من از جسد برآید\n",
            "5 : گوی توفیق و کرامت در میان افکنده‌اند\n",
            "6 : بیا و سلطنت از ما بخر به مایه حسن\n",
            "7 : بیار باده که عمریست تا من از سر امن\n",
            "8 : وجودم رفت و مهرت همچنان هست\n",
            "9 : گر در خیال خلق پری وار بگذری\n",
            "\n",
            " مصرع اصلی شماره 4:‌ خط مشک بوی و خالت به مناسبت تو گویی\n",
            "0 : آن دم که کار مرغ سحر آه و ناله بود\n",
            "1 : دام تزویر مکن چون دگران قرآن را\n",
            "2 : دردا که راز پنهان خواهد شد آشکارا\n",
            "3 : خازن میکده فردا نکند در بازم\n",
            "4 : که ببستی به چشم سحارت\n",
            "5 : نوک مژگانم به سرخی بر بیاض روی زرد\n",
            "6 : لاجرم ز آتش حرمان و هوس می‌جوشیم\n",
            "7 : تو را سماع نباشد که سوز عشق نبود\n",
            "8 : وفای عهد نگه دار و از جفا بگذر\n",
            "9 : تا ابد جام مرادش همدم جانی بود\n",
            "\n",
            " مصرع اصلی شماره 5:‌ قلم غبار می‌رفت و فروچکید خالی\n",
            "0 : که هم نادیده می‌بینی و هم ننوشته می‌خوانی\n",
            "1 : یاران شنیده‌ام که بیابان گرفته‌اند\n",
            "2 : کاسلام دین لیلی و دیگر ضلالتست\n",
            "3 : حاجت آن به که بر قاضی حاجات بریم\n",
            "4 : با پادشه بگوی که روزی مقدر است\n",
            "5 : آن دم که جعد زلف پریشان برافکند\n",
            "6 : صد جوی آب بسته‌ام از دیده بر کنار\n",
            "7 : خرم تن او که چون روانش\n",
            "8 : دو روح در بدنی چون دو مغز در یک پوست\n",
            "9 : خواب از خمار باده نوشین بامداد\n",
            "\n",
            " مصرع اصلی شماره 6:‌ تو هم این مگوی سعدی که نظر گناه باشد\n",
            "0 : دل که آیینه شاهیست غباری دارد\n",
            "1 : روی مه پیکر او سیر ندیدیم و برفت\n",
            "2 : هنگام نوبت سحرست ای ندیم خیز\n",
            "3 : با همه کروبیان عالم بالا\n",
            "4 : خیره آن دیده که آبش نبرد گریه عشق\n",
            "5 : سنگسان شو در قدم نی همچو آب\n",
            "6 : عاشقان را دوای رنجوری\n",
            "7 : صبر پیدا و جگر خوردن پنهان تا چند\n",
            "8 : عاشقان کشتگان معشوقند\n",
            "9 : و اکنون شدم به مستان چون ابروی تو مایل\n",
            "\n",
            " مصرع اصلی شماره 7:‌ گنه‌ست برگرفتن نظر از چنین جمالی\n",
            "0 : عشرت شبگیر کن می نوش کاندر راه عشق\n",
            "1 : خبر دل شنفتنم هوس است\n",
            "2 : ما را که غرقه‌ایم ندانی چه حالتست\n",
            "3 : اول آخر در صبوری اندکی پایاب داشت\n",
            "4 : حسن اندامت نمی‌گویم به شرح\n",
            "5 : دلم رفت و ندیدم روی دلدار\n",
            "6 : بعد از آن نامت به رسوایی برآید ننگ نیست\n",
            "7 : بنده خویشتنم خوان که به شاهی برسم\n",
            "8 : ای روی تو از بهشت بابی\n",
            "9 : الا ای ساروان منزل دوست\n",
            "\n",
            " مصرع اصلی شماره 8:‌ ترحم ذلتی یا ذا المعالی\n",
            "0 : خورشید چو آن خال سیه دید به دل گفت\n",
            "1 : تو باز دعوی پرهیز می‌کنی سعدی\n",
            "2 : هزار دشمن اگر در قفاست عارف را\n",
            "3 : کجا روم که نمی‌باشدم گزیر از دوست\n",
            "4 : ز چمن نرست سروی که ز بیخ برنکندش\n",
            "5 : بار جورت می‌برم گر چه تواناییم نیست\n",
            "6 : کجا یابم وصال چون تو شاهی\n",
            "7 : حیف است بلبلی چو من اکنون در این قفس\n",
            "8 : پادشاهان به غلط یاد گدا نیز کنند\n",
            "9 : که یک کرشمه تلافی صد جفا بکند\n",
            "\n",
            " مصرع اصلی شماره 9:‌ و واصلنی اذا شوشت حالی\n",
            "0 : تو باز دعوی پرهیز می‌کنی سعدی\n",
            "1 : کجا روم که نمی‌باشدم گزیر از دوست\n",
            "2 : ز چمن نرست سروی که ز بیخ برنکندش\n",
            "3 : دیبای جمال تو به بازار برآمد\n",
            "4 : ثوابت باشد ای دارای خرمن\n",
            "5 : بار جورت می‌برم گر چه تواناییم نیست\n",
            "6 : ای عزیز من نه عیب آن به که پنهانی بود\n",
            "7 : آدمی نیست مگر کالبدی بی‌جانست\n",
            "8 : کجا یابم وصال چون تو شاهی\n",
            "9 : حالیا رفتیم و تخمی کاشتیم\n",
            "\n",
            " مصرع اصلی شماره 10:‌ الا یا ناعس الطرفین سکری\n",
            "0 : حالیا رفتیم و تخمی کاشتیم\n",
            "1 : ساقی بیا که نیست ز دوزخ شکایتی\n",
            "2 : صلح کردیم که ما را سر پیکار تو نیست\n",
            "3 : زان جا که پرده پوشی عفو کریم توست\n",
            "4 : درد دل با تو همان به که نگوید درویش\n",
            "5 : هوشم نماند و عقل برفت و سخن ببست\n",
            "6 : سعدیا گوشه نشینی کن و شاهدبازی\n",
            "7 : آدمی نیست مگر کالبدی بی‌جانست\n",
            "8 : روزی برود روان سعدی\n",
            "9 : کدام محرم دل ره در این حرم دارد\n",
            "\n",
            " مصرع اصلی شماره 11:‌ سل السهران عن طول اللیالی\n",
            "0 : حیف است بلبلی چو من اکنون در این قفس\n",
            "1 : گله از دست بوستانبانت\n",
            "2 : کجا روم که نمی‌باشدم گزیر از دوست\n",
            "3 : خورشید چو آن خال سیه دید به دل گفت\n",
            "4 : هزار دشمن اگر در قفاست عارف را\n",
            "5 : این را شکیب نیست گر آن را ملالتست\n",
            "6 : ز چمن نرست سروی که ز بیخ برنکندش\n",
            "7 : سنگ سیه صورت نگین نپذیرد\n",
            "8 : پادشاهان به غلط یاد گدا نیز کنند\n",
            "9 : بار جورت می‌برم گر چه تواناییم نیست\n",
            "\n",
            " مصرع اصلی شماره 12:‌ ندارم چون تو در عالم دگر دوست\n",
            "0 : ای آفتاب سایه ز ما برمدار هم\n",
            "1 : یا بتواند گریخت آن که به زندان اوست\n",
            "2 : من گدا هوس سروقامتی دارم\n",
            "3 : فما تطیب نفسی و ما استطاب منامی\n",
            "4 : من بر آن بودم که ندهم دل به عشق\n",
            "5 : اگر آن عهدشکن با سر میثاق آید\n",
            "6 : عمر بگذشته به پیرانه سرم بازآید\n",
            "7 : هر آن که راز دو عالم ز خط ساغر خواند\n",
            "8 : حافظا سر ز کله گوشه خورشید برآر\n",
            "9 : زهد رندان نوآموخته راهی بدهیست\n",
            "\n",
            " مصرع اصلی شماره 13:‌ اگر چه دوستی دشمن فعالی\n",
            "0 : روزه هر چند که مهمان عزیز است ای دل\n",
            "1 : شمشاد خرامان کن تا باغ بیارایی\n",
            "2 : می‌رود تا در کمند افتد به پای خویشتن\n",
            "3 : معلمت همه شوخی و دلبری آموخت\n",
            "4 : خواهم اندر عقبش رفت به یاران عزیز\n",
            "5 : قصد هلاک مردم هشیار می‌کند\n",
            "6 : تو می‌روی و خبر نداری\n",
            "7 : بوسه بر درج عقیق تو حلال است مرا\n",
            "8 : لبم بر لب نه ای ساقی و بستان جان شیرینم\n",
            "9 : بجست و در دل مردان هوشیار آید\n",
            "\n",
            " مصرع اصلی شماره 14:‌ کمال الحسن فی الدنیا مصون\n",
            "0 : خوشا دلی که مدام از پی نظر نرود\n",
            "1 : سعدیا گوشه نشینی کن و شاهدبازی\n",
            "2 : هوشم نماند و عقل برفت و سخن ببست\n",
            "3 : عهد با پیمانه بندم شرط با ساغر کنم\n",
            "4 : لیکن بر ابروانش سحر مبین نباشد\n",
            "5 : واله شود کبک دری طاووس شهپر برکند\n",
            "6 : آسمان بار امانت نتوانست کشید\n",
            "7 : ور خود از تخمه جمشید و فریدون باشی\n",
            "8 : ای عزیز من نه عیب آن به که پنهانی بود\n",
            "9 : و علم الله حسبی من سؤالی\n",
            "\n",
            " مصرع اصلی شماره 15:‌ کمثل البدر فی حد الکمال\n",
            "0 : حیف است بلبلی چو من اکنون در این قفس\n",
            "1 : هوشم نماند و عقل برفت و سخن ببست\n",
            "2 : این را شکیب نیست گر آن را ملالتست\n",
            "3 : ز چمن نرست سروی که ز بیخ برنکندش\n",
            "4 : کجا روم که نمی‌باشدم گزیر از دوست\n",
            "5 : خورشید چو آن خال سیه دید به دل گفت\n",
            "6 : پادشاهان به غلط یاد گدا نیز کنند\n",
            "7 : هزار دشمن اگر در قفاست عارف را\n",
            "8 : ای عزیز من نه عیب آن به که پنهانی بود\n",
            "9 : گله از دست بوستانبانت\n",
            "\n",
            " مصرع اصلی شماره 16:‌ مرکب در وجودم همچو جانی\n",
            "0 : همچنان عاشق نباشد ور بود صادق نباشد\n",
            "1 : به درد و صاف تو را حکم نیست خوش درکش\n",
            "2 : طاقت بار ستم تا کی و هجران تا چند\n",
            "3 : چمن حکایت اردیبهشت می‌گوید\n",
            "4 : آستین از چنگ مسکینان گرفتم درکشد\n",
            "5 : فدای خاک در دوست باد جان گرامی\n",
            "6 : این جان عاریت که به حافظ سپرد دوست\n",
            "7 : دست من گیر که بیچارگی از حد بگذشت\n",
            "8 : که دست قدرت کوتاه ما بر او یازد\n",
            "9 : ندیده‌اند مگر دلبران بت رو را\n",
            "\n",
            " مصرع اصلی شماره 17:‌ مصور در دماغم چون خیالی\n",
            "0 : کیست آن کش سر پیوند تو در خاطر نیست\n",
            "1 : بر من که صبوحی زده‌ام خرقه حرامست\n",
            "2 : دی می‌شد و گفتم صنما عهد به جای آر\n",
            "3 : شهر خالیست ز عشاق بود کز طرفی\n",
            "4 : کآخر نداند بیش از این یا می‌کشد یا می‌برد\n",
            "5 : کلک حافظ شکرین میوه نباتیست به چین\n",
            "6 : شک نیست که بوستان بخندد\n",
            "7 : گر پس از این دمی چنان یابم قدر دانمش\n",
            "8 : به در صومعه با بربط و پیمانه روم\n",
            "9 : ای نسیم صبح اگر باز اتفاقی افتدت\n",
            "\n",
            " مصرع اصلی شماره 18:‌ فما ذالنوم قیل النوم راحه\n",
            "0 : آن که منظور دیده و دل ماست\n",
            "1 : کجا روم که نمی‌باشدم گزیر از دوست\n",
            "2 : حیف است بلبلی چو من اکنون در این قفس\n",
            "3 : من آن شکل صنوبر را ز باغ دیده برکندم\n",
            "4 : هزار دشمن اگر در قفاست عارف را\n",
            "5 : کجا یابم وصال چون تو شاهی\n",
            "6 : جوان بخت جهانم گر چه پیرم\n",
            "7 : که یک کرشمه تلافی صد جفا بکند\n",
            "8 : آدمی نیست مگر کالبدی بی‌جانست\n",
            "9 : ز چمن نرست سروی که ز بیخ برنکندش\n",
            "\n",
            " مصرع اصلی شماره 19:‌ و مالی النوم فی طول اللیالی\n",
            "0 : هوشم نماند و عقل برفت و سخن ببست\n",
            "1 : کجا روم که نمی‌باشدم گزیر از دوست\n",
            "2 : ز چمن نرست سروی که ز بیخ برنکندش\n",
            "3 : حیف است بلبلی چو من اکنون در این قفس\n",
            "4 : این را شکیب نیست گر آن را ملالتست\n",
            "5 : هزار دشمن اگر در قفاست عارف را\n",
            "6 : کجا یابم وصال چون تو شاهی\n",
            "7 : خورشید چو آن خال سیه دید به دل گفت\n",
            "8 : ای عزیز من نه عیب آن به که پنهانی بود\n",
            "9 : گله از دست بوستانبانت\n",
            "\n",
            " مصرع اصلی شماره 20:‌ دمی دلداری و صاحب دلی کن\n",
            "0 : دل از کرشمه ساقی به شکر بود ولی\n",
            "1 : از عظمت ماورای فکرت دانا\n",
            "2 : چه شود گر من و تو چند قدح باده خوریم\n",
            "3 : گر آستین دوست بیفتد به دست من\n",
            "4 : ما مرد زهد و توبه و طامات نیستیم\n",
            "5 : به سر رسید امید و طلب به سر نرسید\n",
            "6 : بگذری ای پیک نسیم صبا\n",
            "7 : یار با یار سفرکرده به تنها نرود\n",
            "8 : سعدی مبر اندیشه که در کام نهنگان\n",
            "9 : من از تو پیش که نالم که در شریعت عشق\n",
            "\n",
            " مصرع اصلی شماره 21:‌ که برخور بادی از صاحب جمالی\n",
            "0 : مرا فتاد دل از ره تو را چه افتادست\n",
            "1 : بنده خویشتنم خوان که به شاهی برسم\n",
            "2 : تو گر ترش بنشینی قضا چه غم دارد\n",
            "3 : بعد از آن نامت به رسوایی برآید ننگ نیست\n",
            "4 : فراغت باشد از شاه و وزیرم\n",
            "5 : شکسته وار به درگاهت آمدم که طبیب\n",
            "6 : گویی که نیشی دور از او در استخوانم می‌رود\n",
            "7 : وین ماجرا به سرو لب جویبار بخش\n",
            "8 : نمی‌باید که وامق را شکایت بر زبان آید\n",
            "9 : که حکم بر سر آزادگان روان داری\n",
            "\n",
            " مصرع اصلی شماره 22:‌ الم تنظر الی عینی و دمعی\n",
            "0 : روی تاجیکانه‌ات بنمای تا داغ حبش\n",
            "1 : گله از دست بوستانبانت\n",
            "2 : که بدین راه بشد یار و ز ما یاد نکرد\n",
            "3 : هیچ کس نیست که مطلوب مرا جویان نیست\n",
            "4 : ز پرده کاش برون آمدی چو قطره اشک\n",
            "5 : اگر چه خرمن عمرم غم تو داد به باد\n",
            "6 : کجا یابم وصال چون تو شاهی\n",
            "7 : کز دست نیکوان همه چیزی نکو بود\n",
            "8 : تو بفرما که من سوخته خرمن چه کنم\n",
            "9 : پادشاهان به غلط یاد گدا نیز کنند\n",
            "\n",
            " مصرع اصلی شماره 23:‌ تری فی البحر اصداف اللالی\n",
            "0 : نظم هر گوهر ناسفته که حافظ را بود\n",
            "1 : خورشید چو آن خال سیه دید به دل گفت\n",
            "2 : که یک کرشمه تلافی صد جفا بکند\n",
            "3 : روی تاجیکانه‌ات بنمای تا داغ حبش\n",
            "4 : پادشاهان به غلط یاد گدا نیز کنند\n",
            "5 : هزار دشمن اگر در قفاست عارف را\n",
            "6 : هیچ کس نیست که مطلوب مرا جویان نیست\n",
            "7 : هرگز به عمر روزی روزی شود وصالی\n",
            "8 : تو بفرما که من سوخته خرمن چه کنم\n",
            "9 : پس زاهدان برای چه خلوت گزیده‌اند\n",
            "\n",
            " مصرع اصلی شماره 24:‌ به گوشت گر رسانم ناله زار\n",
            "0 : عیشست بر کنار سمن زار خواب صبح\n",
            "1 : فضلست اگرم خوانی عدلست اگرم رانی\n",
            "2 : وز دیده دل نمی‌شوی دور\n",
            "3 : وز قد بلند او بالای صنوبر پست\n",
            "4 : رهزن دهر نخفته‌ست مشو ایمن از او\n",
            "5 : دولت در آن سرا و گشایش در آن در است\n",
            "6 : که چشم سعی ضعیفست بی چراغ هدایت\n",
            "7 : نوبهار است در آن کوش که خوشدل باشی\n",
            "8 : کز باد سبق برد عنانت\n",
            "9 : تا هواخواه تو شد فر همایی دارد\n"
          ]
        }
      ]
    }
  ]
}