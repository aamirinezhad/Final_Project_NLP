{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Necessary installations and Imports"
      ],
      "metadata": {
        "id": "XiJO31YACbsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install libomp-dev"
      ],
      "metadata": {
        "id": "rFdUlRC0n-CJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAmqk7rmwVq8"
      },
      "outputs": [],
      "source": [
        "!pip install -q git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q git+https://github.com/gmihaila/ml_things.git\n",
        "!pip install sentence-transformers\n",
        "!pip install datasets\n",
        "!pip install faiss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import random\n",
        "import os\n",
        "import math\n",
        "import torch\n",
        "import warnings\n",
        "from tqdm.notebook import tqdm\n",
        "from ml_things import plot_dict, fix_text\n",
        "from transformers import *\n",
        "from sentence_transformers import util\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "import faiss\n",
        "\n",
        "set_seed(1)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "gAzzUSg-wkre"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROOTPATH = '/content/drive/MyDrive/NlpProject/'"
      ],
      "metadata": {
        "id": "0hL-wF7acS3f"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ogp-O6bXLHF",
        "outputId": "7ffbcd0a-0b6f-490a-f40e-a2bd0d3f59c1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HSRijZmUz_p4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb26823b-aedd-49a2-df8f-24bd05c7d1e4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading the data and making the appropriate text file"
      ],
      "metadata": {
        "id": "bWBKucznCquB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_train(mode = 'mesra', numberOfTrainData = 100):\n",
        "  lines = []\n",
        "  with open(ROOTPATH + 'all_qazals_mesra.txt') as f:\n",
        "    lines = [ x.strip() for x in f.readlines()]\n",
        "\n",
        "  texts = []\n",
        "  if mode=='beyt':\n",
        "    for i in range(1,len(lines),2):\n",
        "      texts.append(lines[i-1]+'.'+lines[i])\n",
        "  elif mode=='mesra':\n",
        "    texts = lines\n",
        "\n",
        "\n",
        "  all_texts = '\\n'.join(texts[:min(len(lines),numberOfTrainData)])\n",
        "\n",
        "  io.open(file= ROOTPATH + 'train.txt', mode='w', encoding='utf-8').write(all_texts)\n",
        "  return texts"
      ],
      "metadata": {
        "id": "oJQJGRUyznWV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = create_train(mode = 'mesra', numberOfTrainData = 329707)"
      ],
      "metadata": {
        "id": "DyV1nVVuazPi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fine tuning the model"
      ],
      "metadata": {
        "id": "5p6B0avlDJ7O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Helper fuctions and classes"
      ],
      "metadata": {
        "id": "pOvfWB95C4g_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelDataArguments(object):\n",
        "  def __init__(self, train_data_file=None, \n",
        "               line_by_line=False, mlm=False, mlm_probability=0.15, \n",
        "               whole_word_mask=False, max_span_length=5,\n",
        "               block_size=-1, tokenizer_name=None, \n",
        "               model_name_or_path=None):\n",
        "    \n",
        "    self.train_data_file = train_data_file\n",
        "    self.line_by_line = line_by_line\n",
        "    self.mlm = mlm\n",
        "    self.whole_word_mask = whole_word_mask\n",
        "    self.mlm_probability = mlm_probability\n",
        "    self.max_span_length = max_span_length\n",
        "    self.block_size = block_size\n",
        "    self.tokenizer_name = tokenizer_name\n",
        "    self.model_name_or_path = model_name_or_path\n",
        "    return\n",
        "\n",
        "\n",
        "def get_model_config(args: ModelDataArguments):\n",
        "  model_config = AutoConfig.from_pretrained(args.model_name_or_path)\n",
        "  return model_config\n",
        "\n",
        "\n",
        "def get_tokenizer(args: ModelDataArguments):\n",
        "  if args.tokenizer_name:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(args.tokenizer_name)\n",
        "\n",
        "  # Dont go beyond tokenizer maximum length.\n",
        "  args.block_size = min(args.block_size, tokenizer.model_max_length)\n",
        "\n",
        "  return tokenizer\n",
        "  \n",
        "\n",
        "def get_model(args: ModelDataArguments, model_config):\n",
        "  if type(model_config) in MODEL_FOR_MASKED_LM_MAPPING.keys():\n",
        "    return AutoModelForMaskedLM.from_pretrained(args.model_name_or_path, from_tf=bool(\".ckpt\" in args.model_name_or_path), config=model_config)\n",
        "\n",
        "\n",
        "def get_dataset(args: ModelDataArguments, tokenizer: PreTrainedTokenizer, evaluate: bool=False):\n",
        "  file_path = args.train_data_file\n",
        "  if args.line_by_line:\n",
        "    return LineByLineTextDataset(tokenizer=tokenizer, file_path=file_path,block_size=args.block_size)\n",
        "\n",
        "  else:\n",
        "    return TextDataset(tokenizer=tokenizer, file_path=file_path,block_size=args.block_size)\n",
        "\n",
        "def get_collator(args: ModelDataArguments, model_config: PretrainedConfig,tokenizer: PreTrainedTokenizer):\n",
        "  return DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=args.mlm, mlm_probability=args.mlm_probability,)\n"
      ],
      "metadata": {
        "id": "SE9sTfpUwu_n"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Defining the arguments"
      ],
      "metadata": {
        "id": "76LKNneHDR-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_data_args = ModelDataArguments(\n",
        "                                    train_data_file= ROOTPATH + 'train.txt', \n",
        "                                    line_by_line=True, \n",
        "                                    mlm=True,\n",
        "                                    whole_word_mask=True,\n",
        "                                    mlm_probability=0.15,\n",
        "                                    max_span_length=5,\n",
        "                                    block_size=50, \n",
        "                                    tokenizer_name='SajjadAyoubi/distil-bigbird-fa-zwnj', \n",
        "                                    model_name_or_path=\"SajjadAyoubi/distil-bigbird-fa-zwnj\", \n",
        "                                    )\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "                          output_dir=ROOTPATH + 'pretrain_persianbigbird',\n",
        "                          overwrite_output_dir=True,\n",
        "                          do_train=True, \n",
        "                          per_device_train_batch_size=10,\n",
        "                          prediction_loss_only=True,\n",
        "                          learning_rate = 5e-5,\n",
        "                          weight_decay=0,\n",
        "                          adam_epsilon = 1e-8,\n",
        "                          max_grad_norm = 1.0,\n",
        "                          num_train_epochs = 2,\n",
        "                          save_steps = -1,\n",
        "                          )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kwaGCZ2x51i",
        "outputId": "9a00aed1-d8ac-48d2-8f17-2723ea5f1878"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Loading the model and the tokenizer"
      ],
      "metadata": {
        "id": "VcOovJZeDZRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Loading model configuration...')\n",
        "config = get_model_config(model_data_args)\n",
        "\n",
        "print('Loading model`s tokenizer...')\n",
        "tokenizer = get_tokenizer(model_data_args)\n",
        "\n",
        "print('Loading actual model...')\n",
        "model = get_model(model_data_args, config)\n",
        "\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "metadata": {
        "id": "JOnkI_EXykkU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc564897-b4a4-4d26-e776-195b438a1d4e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model configuration...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--SajjadAyoubi--distil-bigbird-fa-zwnj/snapshots/98fd06440980957e6428dc823e16d56593fb805c/config.json\n",
            "Model config BigBirdConfig {\n",
            "  \"_name_or_path\": \"SajjadAyoubi/distil-bigbird-fa-zwnj\",\n",
            "  \"architectures\": [\n",
            "    \"BigBirdForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"attention_type\": \"block_sparse\",\n",
            "  \"block_size\": 32,\n",
            "  \"bos_token_id\": null,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 4096,\n",
            "  \"model_type\": \"big_bird\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"num_random_blocks\": 3,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"rescale_embeddings\": false,\n",
            "  \"sep_token_id\": 3,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.22.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bias\": true,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 42000\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model`s tokenizer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--SajjadAyoubi--distil-bigbird-fa-zwnj/snapshots/98fd06440980957e6428dc823e16d56593fb805c/vocab.txt\n",
            "loading file tokenizer.json from cache at None\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--SajjadAyoubi--distil-bigbird-fa-zwnj/snapshots/98fd06440980957e6428dc823e16d56593fb805c/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--SajjadAyoubi--distil-bigbird-fa-zwnj/snapshots/98fd06440980957e6428dc823e16d56593fb805c/tokenizer_config.json\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--SajjadAyoubi--distil-bigbird-fa-zwnj/snapshots/98fd06440980957e6428dc823e16d56593fb805c/pytorch_model.bin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading actual model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint weights were used when initializing BigBirdForMaskedLM.\n",
            "\n",
            "Some weights of BigBirdForMaskedLM were not initialized from the model checkpoint at SajjadAyoubi/distil-bigbird-fa-zwnj and are newly initialized: ['bert.pooler.weight', 'bert.pooler.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(42000, 768, padding_idx=0)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating train dataset"
      ],
      "metadata": {
        "id": "0mun4ailDgzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Creating train dataset...')\n",
        "train_dataset = get_dataset(model_data_args, tokenizer=tokenizer)\n",
        "data_collator = get_collator(model_data_args, config, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "403SKw9tyo8N",
        "outputId": "ca765e4d-f908-4a1d-a2b6-afdc240e398b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:125: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  FutureWarning,\n",
            "Creating features from dataset file at /content/drive/MyDrive/NlpProject/train.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating train dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "adeSBp3bDzB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mode = 'test'\n",
        "if mode == 'train':\n",
        "  print('Loading `trainer`...')\n",
        "  trainer = Trainer(model=model,\n",
        "                    args=training_args,\n",
        "                    data_collator=data_collator,\n",
        "                    train_dataset=train_dataset)\n",
        "\n",
        "  if training_args.do_train:\n",
        "    print('Start training...')\n",
        "    model_path = (model_data_args.model_name_or_path \n",
        "                  if model_data_args.model_name_or_path is not None and \n",
        "                  os.path.isdir(model_data_args.model_name_or_path) \n",
        "                  else None\n",
        "                  )\n",
        "    trainer.train(model_path=model_path)\n",
        "    trainer.save_model()\n",
        "else:\n",
        "  model.load_state_dict(torch.load(ROOTPATH + \"pretrain_persianbigbird/pytorch_model.bin\", map_location=torch.device('cuda')))"
      ],
      "metadata": {
        "id": "sxrHR5Jhyu0T"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(texts)"
      ],
      "metadata": {
        "id": "jfmanE8yGFaC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be66a6d1-f1c3-45e6-f3c2-c89e447bdbe4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "329707"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TESTING THE CODE"
      ],
      "metadata": {
        "id": "WNjqzDCNyTgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "def knn_score(train_set, test_set, n_neighbours=1):\n",
        "    \"\"\"\n",
        "    Calculates the KNN distance\n",
        "    \"\"\"\n",
        "    train_set=train_set.detach().cpu().numpy()\n",
        "    test_set=test_set.detach().cpu().numpy()\n",
        "    index = faiss.IndexFlatL2(train_set.shape[1])\n",
        "    index.add(train_set)\n",
        "    D, idx_ = index.search(test_set, n_neighbours)\n",
        "    return idx_\n",
        "    \n",
        "def input_to_feature(input_,model):\n",
        "    text_preprocessed = input_\n",
        "    encoded = tokenizer.batch_encode_plus([text_preprocessed],max_length=50, padding='max_length', truncation=True)\n",
        "    encoded = {key:torch.LongTensor(value) for key, value in encoded.items()}\n",
        "    encoded['input_ids']=encoded['input_ids'].cuda()\n",
        "    encoded['token_type_ids']=encoded['token_type_ids'].cuda()\n",
        "    encoded['attention_mask']=encoded['attention_mask'].cuda()\n",
        "    with torch.no_grad(): \n",
        "            outputs = model(**encoded)\n",
        "    feature_outputs = outputs[0].mean(1)\n",
        "    return feature_outputs\n",
        "\n",
        "\n",
        "\n",
        "def training_set_feature_bank(model,Data):\n",
        "        \n",
        "    feature_bank=[]\n",
        " \n",
        "    batch_size = 10  \n",
        "    for idx in range(0, len(Data ), batch_size):\n",
        "        batch = Data [idx : min(len( Data), idx+batch_size)]\n",
        "        \n",
        "        # encoded = tokenizer(batch)\n",
        "        \n",
        "        encoded = tokenizer(batch,max_length=50, padding='max_length', truncation=True)\n",
        "    \n",
        "        encoded = {key:torch.LongTensor(value) for key, value in encoded.items()}\n",
        "        encoded['input_ids']=encoded['input_ids'].cuda()\n",
        "        # encoded['token_type_ids']=encoded['token_type_ids'].cuda()\n",
        "        encoded['attention_mask']=encoded['attention_mask'].cuda()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            \n",
        "            outputs = model(**encoded)\n",
        "            \n",
        "            feature_bank.append(outputs[0].mean(1))\n",
        "\n",
        "    feature_bank_t=torch.cat(feature_bank)\n",
        "    return feature_bank_t"
      ],
      "metadata": {
        "id": "P0dWiSjSPXY4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = random.sample(texts, 15000)\n",
        "queries = texts[20000:20025]"
      ],
      "metadata": {
        "id": "14r2Lf2XPtHt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "feature_bank = training_set_feature_bank(model.cuda(), docs)\n",
        "test_feature_bank = training_set_feature_bank(model, queries)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UytqpW3IPXUS",
        "outputId": "507cf147-772b-446d-da42-93a06dc6aa50"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Attention type 'block_sparse' is not possible if sequence_length: 50 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 352 with config.block_size = 32, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "def find_most_similar(_test_sentences_embedding, _train_sentences_embedding, _number_of_neighbors):\n",
        "  knn = NearestNeighbors(n_neighbors=_number_of_neighbors)\n",
        "  knn.fit(_train_sentences_embedding)\n",
        "  most_similar = knn.kneighbors(_test_sentences_embedding) \n",
        "  return most_similar"
      ],
      "metadata": {
        "id": "cxA92iilPXP-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "most_similar = find_most_similar(test_feature_bank.cpu(), feature_bank.cpu(), 10)"
      ],
      "metadata": {
        "id": "q-yqz8edPXL1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for main_sent_index, main_sent in enumerate(most_similar[1]):\n",
        "  print(\"\\n Ù…ØµØ±Ø¹ Ø§ØµÙ„ÛŒ Ø´Ù…Ø§Ø±Ù‡ \" + str(main_sent_index) + \":â€Œ \" + queries[main_sent_index])\n",
        "  for close_sent_index, close_sent in enumerate(main_sent):\n",
        "    print(str(close_sent_index) + \" : \" + texts[close_sent])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GShr8_mKPXHh",
        "outputId": "eece4506-1b44-4f6b-f52b-9b2b26631e09"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Ù…ØµØ±Ø¹ Ø§ØµÙ„ÛŒ Ø´Ù…Ø§Ø±Ù‡ 0:â€Œ Ú©Ù‡ Ù†Ù‡ Ø§Ù…Ø´Ø¨ Ø¢Ù† Ø³Ù…Ø§Ø¹Ø³Øª Ú©Ù‡ Ø¯Ù Ø®Ù„Ø§Øµ ÛŒØ§Ø¨Ø¯\n",
            "0 : Ø¯ÛŒØ¯Ø§Ø± Ø¯ÙˆØ³ØªØ§Ù† Ú©Ù‡ Ø¨Ø¨ÛŒÙ†Ù†Ø¯ Ù…Ø±Ù‡Ù…Ø³Øª\n",
            "1 : Ø¯ÙˆØ´Ù… Ø¢Ù† Ø³Ù†Ú¯ Ø¯Ù„ Ù¾Ø±ÛŒØ´Ø§Ù† Ø¯Ø§Ø´Øª\n",
            "2 : Ù‡Ø± Ú©Ø¬Ø§ Ù‡Ø³Øª Ø®Ø¯Ø§ÛŒØ§ Ø¨Ù‡ Ø³Ù„Ø§Ù…Øª Ø¯Ø§Ø±Ø´\n",
            "3 : Ú†Ù‡ Ù†ØµÛŒØ¨Øª Ø² Ø¨Ù„Ø¨Ù„ Ø³Ø­Ø±Ø³Øª\n",
            "4 : Ú†Ù‡ Ø¹Ø°Ø± Ø¨Ø®Øª Ø®ÙˆØ¯ Ú¯ÙˆÛŒÙ… Ú©Ù‡ Ø¢Ù† Ø¹ÛŒØ§Ø± Ø´Ù‡Ø±Ø¢Ø´ÙˆØ¨\n",
            "5 : Ø¯Ø±Ø¯ÛŒØ³Øª Ø¯Ø± Ø¯Ù„Ù… Ú©Ù‡ Ø² Ø¯ÛŒÙˆØ§Ø± Ø¨Ú¯Ø°Ø±Ø¯\n",
            "6 : Ø¯Ø± Ù¾Ø³ Ø¢ÛŒÙ†Ù‡ Ø·ÙˆØ·ÛŒ ØµÙØªÙ… Ø¯Ø§Ø´ØªÙ‡â€ŒØ§Ù†Ø¯\n",
            "7 : Ø¨Ø§Ø² Ø¸ÙØ± Ø¨Ù‡ Ø¯Ø³Øª Ùˆ Ø´Ú©Ø§Ø±ÛŒ Ù†Ù…ÛŒâ€ŒÚ©Ù†ÛŒ\n",
            "8 : Ø¨Ø§Ù„Ù„Ù‡ Ú©Ø² Ø¢ÙØªØ§Ø¨ ÙÙ„Ú© Ø®ÙˆØ¨ØªØ± Ø´ÙˆÛŒ\n",
            "9 : Ø¹Ø¬Ø¨ Ø§Ø² Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÛŒØ§Ù† Ù…Ù†Øª Ù…ÛŒâ€ŒØ¢ÛŒØ¯\n",
            "\n",
            " Ù…ØµØ±Ø¹ Ø§ØµÙ„ÛŒ Ø´Ù…Ø§Ø±Ù‡ 1:â€Œ Ø¨Ù‡ Ø·Ù¾Ø§Ù†Ú†Ù‡â€ŒØ§ÛŒ Ùˆ Ø¨Ø±Ø¨Ø· Ø¨Ø±Ù‡Ø¯ Ø¨Ù‡ Ú¯ÙˆØ´Ù…Ø§Ù„ÛŒ\n",
            "0 : Ø§Ø² Ø¬Ø±Ø¹Ù‡ ØªÙˆ Ø®Ø§Ú© Ø²Ù…ÛŒÙ† Ø¯Ø± Ùˆ Ù„Ø¹Ù„ ÛŒØ§ÙØª\n",
            "1 : Ù…Ø±Ø§ Ø¨Ù‡ Ø¹Ø´Ù‚ ØªÙˆ Ø§Ù†Ø¯ÛŒØ´Ù‡ Ø§Ø² Ù…Ù„Ø§Ù…Øª Ù†ÛŒØ³Øª\n",
            "2 : Ø¹Ù‚Ù„Ù… Ø§Ù†Ø¯Ø± Ø²Ù…Ø§Ù† Ù†ØµÛŒØ­Øª Ú©Ø±Ø¯\n",
            "3 : ØªØ±Ø³Ù… Ø§ÛŒÙ† Ù†Ú©ØªÙ‡ Ø¨Ù‡ ØªØ­Ù‚ÛŒÙ‚ Ù†Ø¯Ø§Ù†ÛŒ Ø¯Ø§Ù†Ø³Øª\n",
            "4 : Ø² ÙÚ©Ø± Ø¢Ù†Ø§Ù† Ú©Ù‡ Ø¯Ø± ØªØ¯Ø¨ÛŒØ± Ø¯Ø±Ù…Ø§Ù†Ù†Ø¯ Ø¯Ø± Ù…Ø§Ù†Ù†Ø¯\n",
            "5 : Ø¨ÛŒØ§ Ú©Ù‡ Ø¨Ø§ Ø³Ø± Ø²Ù„ÙØª Ù‚Ø±Ø§Ø± Ø®ÙˆØ§Ù‡Ù… Ú©Ø±Ø¯\n",
            "6 : Ø¨ÛŒ Ø±ÙˆÛŒ Ú†Ùˆ Ù…Ø§Ù‡ Ø¢Ù† Ù†Ú¯Ø§Ø±ÛŒÙ†\n",
            "7 : ØµØ¯ Ø¨Ø§Ø± ØªÙˆØ¨Ù‡ Ú©Ø±Ø¯Ù… Ùˆ Ø¯ÛŒÚ¯Ø± Ù†Ù…ÛŒâ€ŒÚ©Ù†Ù…\n",
            "8 : Ù‡Ø²Ø§Ø± ÛŒÙˆØ³Ù Ù…ØµØ±ÛŒ ÙØªØ§Ø¯Ù‡ Ø¯Ø± Ú†Ù‡ Ù…Ø§Ø³Øª\n",
            "9 : Ú¯Ø± Ø¯ÙˆØ³Øª Ù…ÛŒâ€ŒØ¢ÛŒØ¯ Ø¨Ø±Ù… ÛŒØ§ ØªÛŒØº Ø¯Ø´Ù…Ù† Ø¨Ø± Ø³Ø±Ù…\n",
            "\n",
            " Ù…ØµØ±Ø¹ Ø§ØµÙ„ÛŒ Ø´Ù…Ø§Ø±Ù‡ 2:â€Œ Ø¯Ú¯Ø± Ø¢ÙØªØ§Ø¨ Ø±ÙˆÛŒØª Ù…Ù†Ù…Ø§ÛŒ Ø¢Ø³Ù…Ø§Ù† Ø±Ø§\n",
            "0 : Ú©Ù‡ Ù‡Ù…Ù‡ Ø¹Ù…Ø± Ø¯Ø¹Ø§Ú¯ÙˆÛŒ Ùˆ Ù‡ÙˆØ§Ø¯Ø§Ø± ØªÙˆ Ù†ÛŒØ³Øª\n",
            "1 : Ø¬Ø§Ù… Ù…Ø±ØµØ¹ ØªÙˆ Ø¨Ø¯ÛŒÙ† Ø¯Ø± Ø´Ø§Ù‡ÙˆØ§Ø±\n",
            "2 : Ø¯Ø± Ø®Ø±Ù‚Ù‡ Ø²Ù† Ø¢ØªØ´ Ú©Ù‡ Ø®Ù… Ø§Ø¨Ø±ÙˆÛŒ Ø³Ø§Ù‚ÛŒ\n",
            "3 : Ú©Ù‡ Ø¨Ù†Ø¯Ú¯Ø§Ù† Ø¨Ù†ÛŒ Ø³Ø¹Ø¯ Ø®ÙˆØ§Ù† ÛŒØºÙ…Ø§ Ø±Ø§\n",
            "4 : Ù‡Ø± Ù†Ø§ÙÙ‡ Ú©Ù‡ Ø¯Ø± Ø¯Ø³Øª Ù†Ø³ÛŒÙ… Ø³Ø­Ø± Ø§ÙØªØ§Ø¯\n",
            "5 : Ø¨ÙˆÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ø² Ø§ÙˆØ¶Ø§Ø¹ Ø¬Ù‡Ø§Ù† Ù…ÛŒâ€ŒØ´Ù†ÙˆÙ…\n",
            "6 : Ø¹Ú©Ø³ Ø®ÙˆÛŒ Ø¨Ø± Ø¹Ø§Ø±Ø¶Ø´ Ø¨ÛŒÙ† Ú©Ø¢ÙØªØ§Ø¨ Ú¯Ø±Ù… Ø±Ùˆ\n",
            "7 : Ø²Ø¨Ø§Ù†Øª Ø¯Ø±Ú©Ø´ Ø§ÛŒ Ø­Ø§ÙØ¸ Ø²Ù…Ø§Ù†ÛŒ\n",
            "8 : Ù…Ø±Ø§Ø¯ Ø®Ø§Ø·Ø± Ù…Ø§ Ù…Ø´Ú©Ù„Ø³Øª Ùˆ Ù…Ø´Ú©Ù„ Ù†ÛŒØ³Øª\n",
            "9 : Ø§Ù„Ø§ Ú¯Ø±Ø´ Ø¨Ø±Ø§Ù†ÛŒ Ø¹Ù„Øª Ø¬Ø² Ø§ÛŒÙ† Ù†Ø¨Ø§Ø´Ø¯\n",
            "\n",
            " Ù…ØµØ±Ø¹ Ø§ØµÙ„ÛŒ Ø´Ù…Ø§Ø±Ù‡ 3:â€Œ Ú©Ù‡ Ù‚Ù…Ø± Ø² Ø´Ø±Ù…Ø³Ø§Ø±ÛŒ Ø¨Ø´Ú©Ø³Øª Ú†ÙˆÙ† Ù‡Ù„Ø§Ù„ÛŒ\n",
            "0 : Ø§Ø² Ø³Ø± Ø²Ù„Ù Ø¹Ø±ÙˆØ³Ø§Ù† Ú†Ù…Ù† Ø¯Ø³Øª Ø¨Ø¯Ø§Ø±Ø¯\n",
            "1 : Ù¾Ø±Ø¯Ù‡ Ø¨Ø±Ø§Ù†Ø¯Ø§Ø®ØªÛŒ Ú©Ø§Ø± Ø¨Ù‡ Ø§ØªÙ…Ø§Ù… Ø±ÙØª\n",
            "2 : Ø±ÙˆØ² Ù‚ÛŒØ§Ù…Øª Ø²Ù†Ù… Ø®ÛŒÙ…Ù‡ Ø¨Ù‡ Ù¾Ù‡Ù„ÙˆÛŒ Ø¯ÙˆØ³Øª\n",
            "3 : Ø¢Ù† Ú©Ù‡ Ø§Ø² Ø¯Ø³Øª Ù…Ù„Ø§Ù…Øª Ø¨Ù‡ ÙØºØ§Ù† Ù…ÛŒâ€ŒØ¢ÛŒØ¯\n",
            "4 : Ø¨Ø§ Ø¬Ø§Ù† Ù…Ù† Ø§Ø² Ø¬Ø³Ø¯ Ø¨Ø±Ø¢ÛŒØ¯\n",
            "5 : Ú¯ÙˆÛŒ ØªÙˆÙÛŒÙ‚ Ùˆ Ú©Ø±Ø§Ù…Øª Ø¯Ø± Ù…ÛŒØ§Ù† Ø§ÙÚ©Ù†Ø¯Ù‡â€ŒØ§Ù†Ø¯\n",
            "6 : Ø¨ÛŒØ§ Ùˆ Ø³Ù„Ø·Ù†Øª Ø§Ø² Ù…Ø§ Ø¨Ø®Ø± Ø¨Ù‡ Ù…Ø§ÛŒÙ‡ Ø­Ø³Ù†\n",
            "7 : Ø¨ÛŒØ§Ø± Ø¨Ø§Ø¯Ù‡ Ú©Ù‡ Ø¹Ù…Ø±ÛŒØ³Øª ØªØ§ Ù…Ù† Ø§Ø² Ø³Ø± Ø§Ù…Ù†\n",
            "8 : ÙˆØ¬ÙˆØ¯Ù… Ø±ÙØª Ùˆ Ù…Ù‡Ø±Øª Ù‡Ù…Ú†Ù†Ø§Ù† Ù‡Ø³Øª\n",
            "9 : Ú¯Ø± Ø¯Ø± Ø®ÛŒØ§Ù„ Ø®Ù„Ù‚ Ù¾Ø±ÛŒ ÙˆØ§Ø± Ø¨Ú¯Ø°Ø±ÛŒ\n",
            "\n",
            " Ù…ØµØ±Ø¹ Ø§ØµÙ„ÛŒ Ø´Ù…Ø§Ø±Ù‡ 4:â€Œ Ø®Ø· Ù…Ø´Ú© Ø¨ÙˆÛŒ Ùˆ Ø®Ø§Ù„Øª Ø¨Ù‡ Ù…Ù†Ø§Ø³Ø¨Øª ØªÙˆ Ú¯ÙˆÛŒÛŒ\n",
            "0 : Ø¢Ù† Ø¯Ù… Ú©Ù‡ Ú©Ø§Ø± Ù…Ø±Øº Ø³Ø­Ø± Ø¢Ù‡ Ùˆ Ù†Ø§Ù„Ù‡ Ø¨ÙˆØ¯\n",
            "1 : Ø¯Ø§Ù… ØªØ²ÙˆÛŒØ± Ù…Ú©Ù† Ú†ÙˆÙ† Ø¯Ú¯Ø±Ø§Ù† Ù‚Ø±Ø¢Ù† Ø±Ø§\n",
            "2 : Ø¯Ø±Ø¯Ø§ Ú©Ù‡ Ø±Ø§Ø² Ù¾Ù†Ù‡Ø§Ù† Ø®ÙˆØ§Ù‡Ø¯ Ø´Ø¯ Ø¢Ø´Ú©Ø§Ø±Ø§\n",
            "3 : Ø®Ø§Ø²Ù† Ù…ÛŒÚ©Ø¯Ù‡ ÙØ±Ø¯Ø§ Ù†Ú©Ù†Ø¯ Ø¯Ø± Ø¨Ø§Ø²Ù…\n",
            "4 : Ú©Ù‡ Ø¨Ø¨Ø³ØªÛŒ Ø¨Ù‡ Ú†Ø´Ù… Ø³Ø­Ø§Ø±Øª\n",
            "5 : Ù†ÙˆÚ© Ù…Ú˜Ú¯Ø§Ù†Ù… Ø¨Ù‡ Ø³Ø±Ø®ÛŒ Ø¨Ø± Ø¨ÛŒØ§Ø¶ Ø±ÙˆÛŒ Ø²Ø±Ø¯\n",
            "6 : Ù„Ø§Ø¬Ø±Ù… Ø² Ø¢ØªØ´ Ø­Ø±Ù…Ø§Ù† Ùˆ Ù‡ÙˆØ³ Ù…ÛŒâ€ŒØ¬ÙˆØ´ÛŒÙ…\n",
            "7 : ØªÙˆ Ø±Ø§ Ø³Ù…Ø§Ø¹ Ù†Ø¨Ø§Ø´Ø¯ Ú©Ù‡ Ø³ÙˆØ² Ø¹Ø´Ù‚ Ù†Ø¨ÙˆØ¯\n",
            "8 : ÙˆÙØ§ÛŒ Ø¹Ù‡Ø¯ Ù†Ú¯Ù‡ Ø¯Ø§Ø± Ùˆ Ø§Ø² Ø¬ÙØ§ Ø¨Ú¯Ø°Ø±\n",
            "9 : ØªØ§ Ø§Ø¨Ø¯ Ø¬Ø§Ù… Ù…Ø±Ø§Ø¯Ø´ Ù‡Ù…Ø¯Ù… Ø¬Ø§Ù†ÛŒ Ø¨ÙˆØ¯\n",
            "\n",
            " Ù…ØµØ±Ø¹ Ø§ØµÙ„ÛŒ Ø´Ù…Ø§Ø±Ù‡ 5:â€Œ Ù‚Ù„Ù… ØºØ¨Ø§Ø± Ù…ÛŒâ€ŒØ±ÙØª Ùˆ ÙØ±ÙˆÚ†Ú©ÛŒØ¯ Ø®Ø§Ù„ÛŒ\n",
            "0 : Ú©Ù‡ Ù‡Ù… Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ù…ÛŒâ€ŒØ¨ÛŒÙ†ÛŒ Ùˆ Ù‡Ù… Ù†Ù†ÙˆØ´ØªÙ‡ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†ÛŒ\n",
            "1 : ÛŒØ§Ø±Ø§Ù† Ø´Ù†ÛŒØ¯Ù‡â€ŒØ§Ù… Ú©Ù‡ Ø¨ÛŒØ§Ø¨Ø§Ù† Ú¯Ø±ÙØªÙ‡â€ŒØ§Ù†Ø¯\n",
            "2 : Ú©Ø§Ø³Ù„Ø§Ù… Ø¯ÛŒÙ† Ù„ÛŒÙ„ÛŒ Ùˆ Ø¯ÛŒÚ¯Ø± Ø¶Ù„Ø§Ù„ØªØ³Øª\n",
            "3 : Ø­Ø§Ø¬Øª Ø¢Ù† Ø¨Ù‡ Ú©Ù‡ Ø¨Ø± Ù‚Ø§Ø¶ÛŒ Ø­Ø§Ø¬Ø§Øª Ø¨Ø±ÛŒÙ…\n",
            "4 : Ø¨Ø§ Ù¾Ø§Ø¯Ø´Ù‡ Ø¨Ú¯ÙˆÛŒ Ú©Ù‡ Ø±ÙˆØ²ÛŒ Ù…Ù‚Ø¯Ø± Ø§Ø³Øª\n",
            "5 : Ø¢Ù† Ø¯Ù… Ú©Ù‡ Ø¬Ø¹Ø¯ Ø²Ù„Ù Ù¾Ø±ÛŒØ´Ø§Ù† Ø¨Ø±Ø§ÙÚ©Ù†Ø¯\n",
            "6 : ØµØ¯ Ø¬ÙˆÛŒ Ø¢Ø¨ Ø¨Ø³ØªÙ‡â€ŒØ§Ù… Ø§Ø² Ø¯ÛŒØ¯Ù‡ Ø¨Ø± Ú©Ù†Ø§Ø±\n",
            "7 : Ø®Ø±Ù… ØªÙ† Ø§Ùˆ Ú©Ù‡ Ú†ÙˆÙ† Ø±ÙˆØ§Ù†Ø´\n",
            "8 : Ø¯Ùˆ Ø±ÙˆØ­ Ø¯Ø± Ø¨Ø¯Ù†ÛŒ Ú†ÙˆÙ† Ø¯Ùˆ Ù…ØºØ² Ø¯Ø± ÛŒÚ© Ù¾ÙˆØ³Øª\n",
            "9 : Ø®ÙˆØ§Ø¨ Ø§Ø² Ø®Ù…Ø§Ø± Ø¨Ø§Ø¯Ù‡ Ù†ÙˆØ´ÛŒÙ† Ø¨Ø§Ù…Ø¯Ø§Ø¯\n",
            "\n",
            " Ù…ØµØ±Ø¹ Ø§ØµÙ„ÛŒ Ø´Ù…Ø§Ø±Ù‡ 6:â€Œ ØªÙˆ Ù‡Ù… Ø§ÛŒÙ† Ù…Ú¯ÙˆÛŒ Ø³Ø¹Ø¯ÛŒ Ú©Ù‡ Ù†Ø¸Ø± Ú¯Ù†Ø§Ù‡ Ø¨Ø§Ø´Ø¯\n",
            "0 : Ø¯Ù„ Ú©Ù‡ Ø¢ÛŒÛŒÙ†Ù‡ Ø´Ø§Ù‡ÛŒØ³Øª ØºØ¨Ø§Ø±ÛŒ Ø¯Ø§Ø±Ø¯\n",
            "1 : Ø±ÙˆÛŒ Ù…Ù‡ Ù¾ÛŒÚ©Ø± Ø§Ùˆ Ø³ÛŒØ± Ù†Ø¯ÛŒØ¯ÛŒÙ… Ùˆ Ø¨Ø±ÙØª\n",
            "2 : Ù‡Ù†Ú¯Ø§Ù… Ù†ÙˆØ¨Øª Ø³Ø­Ø±Ø³Øª Ø§ÛŒ Ù†Ø¯ÛŒÙ… Ø®ÛŒØ²\n",
            "3 : Ø¨Ø§ Ù‡Ù…Ù‡ Ú©Ø±ÙˆØ¨ÛŒØ§Ù† Ø¹Ø§Ù„Ù… Ø¨Ø§Ù„Ø§\n",
            "4 : Ø®ÛŒØ±Ù‡ Ø¢Ù† Ø¯ÛŒØ¯Ù‡ Ú©Ù‡ Ø¢Ø¨Ø´ Ù†Ø¨Ø±Ø¯ Ú¯Ø±ÛŒÙ‡ Ø¹Ø´Ù‚\n",
            "5 : Ø³Ù†Ú¯Ø³Ø§Ù† Ø´Ùˆ Ø¯Ø± Ù‚Ø¯Ù… Ù†ÛŒ Ù‡Ù…Ú†Ùˆ Ø¢Ø¨\n",
            "6 : Ø¹Ø§Ø´Ù‚Ø§Ù† Ø±Ø§ Ø¯ÙˆØ§ÛŒ Ø±Ù†Ø¬ÙˆØ±ÛŒ\n",
            "7 : ØµØ¨Ø± Ù¾ÛŒØ¯Ø§ Ùˆ Ø¬Ú¯Ø± Ø®ÙˆØ±Ø¯Ù† Ù¾Ù†Ù‡Ø§Ù† ØªØ§ Ú†Ù†Ø¯\n",
            "8 : Ø¹Ø§Ø´Ù‚Ø§Ù† Ú©Ø´ØªÚ¯Ø§Ù† Ù…Ø¹Ø´ÙˆÙ‚Ù†Ø¯\n",
            "9 : Ùˆ Ø§Ú©Ù†ÙˆÙ† Ø´Ø¯Ù… Ø¨Ù‡ Ù…Ø³ØªØ§Ù† Ú†ÙˆÙ† Ø§Ø¨Ø±ÙˆÛŒ ØªÙˆ Ù…Ø§ÛŒÙ„\n",
            "\n",
            " Ù…ØµØ±Ø¹ Ø§ØµÙ„ÛŒ Ø´Ù…Ø§Ø±Ù‡ 7:â€Œ Ú¯Ù†Ù‡â€ŒØ³Øª Ø¨Ø±Ú¯Ø±ÙØªÙ† Ù†Ø¸Ø± Ø§Ø² Ú†Ù†ÛŒÙ† Ø¬Ù…Ø§Ù„ÛŒ\n",
            "0 : Ø¹Ø´Ø±Øª Ø´Ø¨Ú¯ÛŒØ± Ú©Ù† Ù…ÛŒ Ù†ÙˆØ´ Ú©Ø§Ù†Ø¯Ø± Ø±Ø§Ù‡ Ø¹Ø´Ù‚\n",
            "1 : Ø®Ø¨Ø± Ø¯Ù„ Ø´Ù†ÙØªÙ†Ù… Ù‡ÙˆØ³ Ø§Ø³Øª\n",
            "2 : Ù…Ø§ Ø±Ø§ Ú©Ù‡ ØºØ±Ù‚Ù‡â€ŒØ§ÛŒÙ… Ù†Ø¯Ø§Ù†ÛŒ Ú†Ù‡ Ø­Ø§Ù„ØªØ³Øª\n",
            "3 : Ø§ÙˆÙ„ Ø¢Ø®Ø± Ø¯Ø± ØµØ¨ÙˆØ±ÛŒ Ø§Ù†Ø¯Ú©ÛŒ Ù¾Ø§ÛŒØ§Ø¨ Ø¯Ø§Ø´Øª\n",
            "4 : Ø­Ø³Ù† Ø§Ù†Ø¯Ø§Ù…Øª Ù†Ù…ÛŒâ€ŒÚ¯ÙˆÛŒÙ… Ø¨Ù‡ Ø´Ø±Ø­\n",
            "5 : Ø¯Ù„Ù… Ø±ÙØª Ùˆ Ù†Ø¯ÛŒØ¯Ù… Ø±ÙˆÛŒ Ø¯Ù„Ø¯Ø§Ø±\n",
            "6 : Ø¨Ø¹Ø¯ Ø§Ø² Ø¢Ù† Ù†Ø§Ù…Øª Ø¨Ù‡ Ø±Ø³ÙˆØ§ÛŒÛŒ Ø¨Ø±Ø¢ÛŒØ¯ Ù†Ù†Ú¯ Ù†ÛŒØ³Øª\n",
            "7 : Ø¨Ù†Ø¯Ù‡ Ø®ÙˆÛŒØ´ØªÙ†Ù… Ø®ÙˆØ§Ù† Ú©Ù‡ Ø¨Ù‡ Ø´Ø§Ù‡ÛŒ Ø¨Ø±Ø³Ù…\n",
            "8 : Ø§ÛŒ Ø±ÙˆÛŒ ØªÙˆ Ø§Ø² Ø¨Ù‡Ø´Øª Ø¨Ø§Ø¨ÛŒ\n",
            "9 : Ø§Ù„Ø§ Ø§ÛŒ Ø³Ø§Ø±ÙˆØ§Ù† Ù…Ù†Ø²Ù„ Ø¯ÙˆØ³Øª\n",
            "\n",
            " Ù…ØµØ±Ø¹ Ø§ØµÙ„ÛŒ Ø´Ù…Ø§Ø±Ù‡ 8:â€Œ ØªØ±Ø­Ù… Ø°Ù„ØªÛŒ ÛŒØ§ Ø°Ø§ Ø§Ù„Ù…Ø¹Ø§Ù„ÛŒ\n",
            "0 : Ø®ÙˆØ±Ø´ÛŒØ¯ Ú†Ùˆ Ø¢Ù† Ø®Ø§Ù„ Ø³ÛŒÙ‡ Ø¯ÛŒØ¯ Ø¨Ù‡ Ø¯Ù„ Ú¯ÙØª\n",
            "1 : ØªÙˆ Ø¨Ø§Ø² Ø¯Ø¹ÙˆÛŒ Ù¾Ø±Ù‡ÛŒØ² Ù…ÛŒâ€ŒÚ©Ù†ÛŒ Ø³Ø¹Ø¯ÛŒ\n",
            "2 : Ù‡Ø²Ø§Ø± Ø¯Ø´Ù…Ù† Ø§Ú¯Ø± Ø¯Ø± Ù‚ÙØ§Ø³Øª Ø¹Ø§Ø±Ù Ø±Ø§\n",
            "3 : Ú©Ø¬Ø§ Ø±ÙˆÙ… Ú©Ù‡ Ù†Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯Ù… Ú¯Ø²ÛŒØ± Ø§Ø² Ø¯ÙˆØ³Øª\n",
            "4 : Ø² Ú†Ù…Ù† Ù†Ø±Ø³Øª Ø³Ø±ÙˆÛŒ Ú©Ù‡ Ø² Ø¨ÛŒØ® Ø¨Ø±Ù†Ú©Ù†Ø¯Ø´\n",
            "5 : Ø¨Ø§Ø± Ø¬ÙˆØ±Øª Ù…ÛŒâ€ŒØ¨Ø±Ù… Ú¯Ø± Ú†Ù‡ ØªÙˆØ§Ù†Ø§ÛŒÛŒÙ… Ù†ÛŒØ³Øª\n",
            "6 : Ú©Ø¬Ø§ ÛŒØ§Ø¨Ù… ÙˆØµØ§Ù„ Ú†ÙˆÙ† ØªÙˆ Ø´Ø§Ù‡ÛŒ\n",
            "7 : Ø­ÛŒÙ Ø§Ø³Øª Ø¨Ù„Ø¨Ù„ÛŒ Ú†Ùˆ Ù…Ù† Ø§Ú©Ù†ÙˆÙ† Ø¯Ø± Ø§ÛŒÙ† Ù‚ÙØ³\n",
            "8 : Ù¾Ø§Ø¯Ø´Ø§Ù‡Ø§Ù† Ø¨Ù‡ ØºÙ„Ø· ÛŒØ§Ø¯ Ú¯Ø¯Ø§ Ù†ÛŒØ² Ú©Ù†Ù†Ø¯\n",
            "9 : Ú©Ù‡ ÛŒÚ© Ú©Ø±Ø´Ù…Ù‡ ØªÙ„Ø§ÙÛŒ ØµØ¯ Ø¬ÙØ§ Ø¨Ú©Ù†Ø¯\n",
            "\n",
            " Ù…ØµØ±Ø¹ Ø§ØµÙ„ÛŒ Ø´Ù…Ø§Ø±Ù‡ 9:â€Œ Ùˆ ÙˆØ§ØµÙ„Ù†ÛŒ Ø§Ø°Ø§ Ø´ÙˆØ´Øª Ø­Ø§Ù„ÛŒ\n",
            "0 : ØªÙˆ Ø¨Ø§Ø² Ø¯Ø¹ÙˆÛŒ Ù¾Ø±Ù‡ÛŒØ² Ù…ÛŒâ€ŒÚ©Ù†ÛŒ Ø³Ø¹Ø¯ÛŒ\n",
            "1 : Ú©Ø¬Ø§ Ø±ÙˆÙ… Ú©Ù‡ Ù†Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯Ù… Ú¯Ø²ÛŒØ± Ø§Ø² Ø¯ÙˆØ³Øª\n",
            "2 : Ø² Ú†Ù…Ù† Ù†Ø±Ø³Øª Ø³Ø±ÙˆÛŒ Ú©Ù‡ Ø² Ø¨ÛŒØ® Ø¨Ø±Ù†Ú©Ù†Ø¯Ø´\n",
            "3 : Ø¯ÛŒØ¨Ø§ÛŒ Ø¬Ù…Ø§Ù„ ØªÙˆ Ø¨Ù‡ Ø¨Ø§Ø²Ø§Ø± Ø¨Ø±Ø¢Ù…Ø¯\n",
            "4 : Ø«ÙˆØ§Ø¨Øª Ø¨Ø§Ø´Ø¯ Ø§ÛŒ Ø¯Ø§Ø±Ø§ÛŒ Ø®Ø±Ù…Ù†\n",
            "5 : Ø¨Ø§Ø± Ø¬ÙˆØ±Øª Ù…ÛŒâ€ŒØ¨Ø±Ù… Ú¯Ø± Ú†Ù‡ ØªÙˆØ§Ù†Ø§ÛŒÛŒÙ… Ù†ÛŒØ³Øª\n",
            "6 : Ø§ÛŒ Ø¹Ø²ÛŒØ² Ù…Ù† Ù†Ù‡ Ø¹ÛŒØ¨ Ø¢Ù† Ø¨Ù‡ Ú©Ù‡ Ù¾Ù†Ù‡Ø§Ù†ÛŒ Ø¨ÙˆØ¯\n",
            "7 : Ø¢Ø¯Ù…ÛŒ Ù†ÛŒØ³Øª Ù…Ú¯Ø± Ú©Ø§Ù„Ø¨Ø¯ÛŒ Ø¨ÛŒâ€ŒØ¬Ø§Ù†Ø³Øª\n",
            "8 : Ú©Ø¬Ø§ ÛŒØ§Ø¨Ù… ÙˆØµØ§Ù„ Ú†ÙˆÙ† ØªÙˆ Ø´Ø§Ù‡ÛŒ\n",
            "9 : Ø­Ø§Ù„ÛŒØ§ Ø±ÙØªÛŒÙ… Ùˆ ØªØ®Ù…ÛŒ Ú©Ø§Ø´ØªÛŒÙ…\n",
            "\n",
            " Ù…ØµØ±Ø¹ Ø§ØµÙ„ÛŒ Ø´Ù…Ø§Ø±Ù‡ 10:â€Œ Ø§Ù„Ø§ ÛŒØ§ Ù†Ø§Ø¹Ø³ Ø§Ù„Ø·Ø±ÙÛŒÙ† Ø³Ú©Ø±ÛŒ\n",
            "0 : Ø­Ø§Ù„ÛŒØ§ Ø±ÙØªÛŒÙ… Ùˆ ØªØ®Ù…ÛŒ Ú©Ø§Ø´ØªÛŒÙ…\n",
            "1 : Ø³Ø§Ù‚ÛŒ Ø¨ÛŒØ§ Ú©Ù‡ Ù†ÛŒØ³Øª Ø² Ø¯ÙˆØ²Ø® Ø´Ú©Ø§ÛŒØªÛŒ\n",
            "2 : ØµÙ„Ø­ Ú©Ø±Ø¯ÛŒÙ… Ú©Ù‡ Ù…Ø§ Ø±Ø§ Ø³Ø± Ù¾ÛŒÚ©Ø§Ø± ØªÙˆ Ù†ÛŒØ³Øª\n",
            "3 : Ø²Ø§Ù† Ø¬Ø§ Ú©Ù‡ Ù¾Ø±Ø¯Ù‡ Ù¾ÙˆØ´ÛŒ Ø¹ÙÙˆ Ú©Ø±ÛŒÙ… ØªÙˆØ³Øª\n",
            "4 : Ø¯Ø±Ø¯ Ø¯Ù„ Ø¨Ø§ ØªÙˆ Ù‡Ù…Ø§Ù† Ø¨Ù‡ Ú©Ù‡ Ù†Ú¯ÙˆÛŒØ¯ Ø¯Ø±ÙˆÛŒØ´\n",
            "5 : Ù‡ÙˆØ´Ù… Ù†Ù…Ø§Ù†Ø¯ Ùˆ Ø¹Ù‚Ù„ Ø¨Ø±ÙØª Ùˆ Ø³Ø®Ù† Ø¨Ø¨Ø³Øª\n",
            "6 : Ø³Ø¹Ø¯ÛŒØ§ Ú¯ÙˆØ´Ù‡ Ù†Ø´ÛŒÙ†ÛŒ Ú©Ù† Ùˆ Ø´Ø§Ù‡Ø¯Ø¨Ø§Ø²ÛŒ\n",
            "7 : Ø¢Ø¯Ù…ÛŒ Ù†ÛŒØ³Øª Ù…Ú¯Ø± Ú©Ø§Ù„Ø¨Ø¯ÛŒ Ø¨ÛŒâ€ŒØ¬Ø§Ù†Ø³Øª\n",
            "8 : Ø±ÙˆØ²ÛŒ Ø¨Ø±ÙˆØ¯ Ø±ÙˆØ§Ù† Ø³Ø¹Ø¯ÛŒ\n",
            "9 : Ú©Ø¯Ø§Ù… Ù…Ø­Ø±Ù… Ø¯Ù„ Ø±Ù‡ Ø¯Ø± Ø§ÛŒÙ† Ø­Ø±Ù… Ø¯Ø§Ø±Ø¯\n",
            "\n",
            " Ù…ØµØ±Ø¹ Ø§ØµÙ„ÛŒ Ø´Ù…Ø§Ø±Ù‡ 11:â€Œ Ø³Ù„ Ø§Ù„Ø³Ù‡Ø±Ø§Ù† Ø¹Ù† Ø·ÙˆÙ„ Ø§Ù„Ù„ÛŒØ§Ù„ÛŒ\n",
            "0 : Ø­ÛŒÙ Ø§Ø³Øª Ø¨Ù„Ø¨Ù„ÛŒ Ú†Ùˆ Ù…Ù† Ø§Ú©Ù†ÙˆÙ† Ø¯Ø± Ø§ÛŒÙ† Ù‚ÙØ³\n",
            "1 : Ú¯Ù„Ù‡ Ø§Ø² Ø¯Ø³Øª Ø¨ÙˆØ³ØªØ§Ù†Ø¨Ø§Ù†Øª\n",
            "2 : Ú©Ø¬Ø§ Ø±ÙˆÙ… Ú©Ù‡ Ù†Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯Ù… Ú¯Ø²ÛŒØ± Ø§Ø² Ø¯ÙˆØ³Øª\n",
            "3 : Ø®ÙˆØ±Ø´ÛŒØ¯ Ú†Ùˆ Ø¢Ù† Ø®Ø§Ù„ Ø³ÛŒÙ‡ Ø¯ÛŒØ¯ Ø¨Ù‡ Ø¯Ù„ Ú¯ÙØª\n",
            "4 : Ù‡Ø²Ø§Ø± Ø¯Ø´Ù…Ù† Ø§Ú¯Ø± Ø¯Ø± Ù‚ÙØ§Ø³Øª Ø¹Ø§Ø±Ù Ø±Ø§\n",
            "5 : Ø§ÛŒÙ† Ø±Ø§ Ø´Ú©ÛŒØ¨ Ù†ÛŒØ³Øª Ú¯Ø± Ø¢Ù† Ø±Ø§ Ù…Ù„Ø§Ù„ØªØ³Øª\n",
            "6 : Ø² Ú†Ù…Ù† Ù†Ø±Ø³Øª Ø³Ø±ÙˆÛŒ Ú©Ù‡ Ø² Ø¨ÛŒØ® Ø¨Ø±Ù†Ú©Ù†Ø¯Ø´\n",
            "7 : Ø³Ù†Ú¯ Ø³ÛŒÙ‡ ØµÙˆØ±Øª Ù†Ú¯ÛŒÙ† Ù†Ù¾Ø°ÛŒØ±Ø¯\n",
            "8 : Ù¾Ø§Ø¯Ø´Ø§Ù‡Ø§Ù† Ø¨Ù‡ ØºÙ„Ø· ÛŒØ§Ø¯ Ú¯Ø¯Ø§ Ù†ÛŒØ² Ú©Ù†Ù†Ø¯\n",
            "9 : Ø¨Ø§Ø± Ø¬ÙˆØ±Øª Ù…ÛŒâ€ŒØ¨Ø±Ù… Ú¯Ø± Ú†Ù‡ ØªÙˆØ§Ù†Ø§ÛŒÛŒÙ… Ù†ÛŒØ³Øª\n",
            "\n",
            " Ù…ØµØ±Ø¹ Ø§ØµÙ„ÛŒ Ø´Ù…Ø§Ø±Ù‡ 12:â€Œ Ù†Ø¯Ø§Ø±Ù… Ú†ÙˆÙ† ØªÙˆ Ø¯Ø± Ø¹Ø§Ù„Ù… Ø¯Ú¯Ø± Ø¯ÙˆØ³Øª\n",
            "0 : Ø§ÛŒ Ø¢ÙØªØ§Ø¨ Ø³Ø§ÛŒÙ‡ Ø² Ù…Ø§ Ø¨Ø±Ù…Ø¯Ø§Ø± Ù‡Ù…\n",
            "1 : ÛŒØ§ Ø¨ØªÙˆØ§Ù†Ø¯ Ú¯Ø±ÛŒØ®Øª Ø¢Ù† Ú©Ù‡ Ø¨Ù‡ Ø²Ù†Ø¯Ø§Ù† Ø§ÙˆØ³Øª\n",
            "2 : Ù…Ù† Ú¯Ø¯Ø§ Ù‡ÙˆØ³ Ø³Ø±ÙˆÙ‚Ø§Ù…ØªÛŒ Ø¯Ø§Ø±Ù…\n",
            "3 : ÙÙ…Ø§ ØªØ·ÛŒØ¨ Ù†ÙØ³ÛŒ Ùˆ Ù…Ø§ Ø§Ø³ØªØ·Ø§Ø¨ Ù…Ù†Ø§Ù…ÛŒ\n",
            "4 : Ù…Ù† Ø¨Ø± Ø¢Ù† Ø¨ÙˆØ¯Ù… Ú©Ù‡ Ù†Ø¯Ù‡Ù… Ø¯Ù„ Ø¨Ù‡ Ø¹Ø´Ù‚\n",
            "5 : Ø§Ú¯Ø± Ø¢Ù† Ø¹Ù‡Ø¯Ø´Ú©Ù† Ø¨Ø§ Ø³Ø± Ù…ÛŒØ«Ø§Ù‚ Ø¢ÛŒØ¯\n",
            "6 : Ø¹Ù…Ø± Ø¨Ú¯Ø°Ø´ØªÙ‡ Ø¨Ù‡ Ù¾ÛŒØ±Ø§Ù†Ù‡ Ø³Ø±Ù… Ø¨Ø§Ø²Ø¢ÛŒØ¯\n",
            "7 : Ù‡Ø± Ø¢Ù† Ú©Ù‡ Ø±Ø§Ø² Ø¯Ùˆ Ø¹Ø§Ù„Ù… Ø² Ø®Ø· Ø³Ø§ØºØ± Ø®ÙˆØ§Ù†Ø¯\n",
            "8 : Ø­Ø§ÙØ¸Ø§ Ø³Ø± Ø² Ú©Ù„Ù‡ Ú¯ÙˆØ´Ù‡ Ø®ÙˆØ±Ø´ÛŒØ¯ Ø¨Ø±Ø¢Ø±\n",
            "9 : Ø²Ù‡Ø¯ Ø±Ù†Ø¯Ø§Ù† Ù†ÙˆØ¢Ù…ÙˆØ®ØªÙ‡ Ø±Ø§Ù‡ÛŒ Ø¨Ø¯Ù‡ÛŒØ³Øª\n",
            "\n",
            " Ù…ØµØ±Ø¹ Ø§ØµÙ„ÛŒ Ø´Ù…Ø§Ø±Ù‡ 13:â€Œ Ø§Ú¯Ø± Ú†Ù‡ Ø¯ÙˆØ³ØªÛŒ Ø¯Ø´Ù…Ù† ÙØ¹Ø§Ù„ÛŒ\n",
            "0 : Ø±ÙˆØ²Ù‡ Ù‡Ø± Ú†Ù†Ø¯ Ú©Ù‡ Ù…Ù‡Ù…Ø§Ù† Ø¹Ø²ÛŒØ² Ø§Ø³Øª Ø§ÛŒ Ø¯Ù„\n",
            "1 : Ø´Ù…Ø´Ø§Ø¯ Ø®Ø±Ø§Ù…Ø§Ù† Ú©Ù† ØªØ§ Ø¨Ø§Øº Ø¨ÛŒØ§Ø±Ø§ÛŒÛŒ\n",
            "2 : Ù…ÛŒâ€ŒØ±ÙˆØ¯ ØªØ§ Ø¯Ø± Ú©Ù…Ù†Ø¯ Ø§ÙØªØ¯ Ø¨Ù‡ Ù¾Ø§ÛŒ Ø®ÙˆÛŒØ´ØªÙ†\n",
            "3 : Ù…Ø¹Ù„Ù…Øª Ù‡Ù…Ù‡ Ø´ÙˆØ®ÛŒ Ùˆ Ø¯Ù„Ø¨Ø±ÛŒ Ø¢Ù…ÙˆØ®Øª\n",
            "4 : Ø®ÙˆØ§Ù‡Ù… Ø§Ù†Ø¯Ø± Ø¹Ù‚Ø¨Ø´ Ø±ÙØª Ø¨Ù‡ ÛŒØ§Ø±Ø§Ù† Ø¹Ø²ÛŒØ²\n",
            "5 : Ù‚ØµØ¯ Ù‡Ù„Ø§Ú© Ù…Ø±Ø¯Ù… Ù‡Ø´ÛŒØ§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯\n",
            "6 : ØªÙˆ Ù…ÛŒâ€ŒØ±ÙˆÛŒ Ùˆ Ø®Ø¨Ø± Ù†Ø¯Ø§Ø±ÛŒ\n",
            "7 : Ø¨ÙˆØ³Ù‡ Ø¨Ø± Ø¯Ø±Ø¬ Ø¹Ù‚ÛŒÙ‚ ØªÙˆ Ø­Ù„Ø§Ù„ Ø§Ø³Øª Ù…Ø±Ø§\n",
            "8 : Ù„Ø¨Ù… Ø¨Ø± Ù„Ø¨ Ù†Ù‡ Ø§ÛŒ Ø³Ø§Ù‚ÛŒ Ùˆ Ø¨Ø³ØªØ§Ù† Ø¬Ø§Ù† Ø´ÛŒØ±ÛŒÙ†Ù…\n",
            "9 : Ø¨Ø¬Ø³Øª Ùˆ Ø¯Ø± Ø¯Ù„ Ù…Ø±Ø¯Ø§Ù† Ù‡ÙˆØ´ÛŒØ§Ø± Ø¢ÛŒØ¯\n",
            "\n",
            " Ù…ØµØ±Ø¹ Ø§ØµÙ„ÛŒ Ø´Ù…Ø§Ø±Ù‡ 14:â€Œ Ú©Ù…Ø§Ù„ Ø§Ù„Ø­Ø³Ù† ÙÛŒ Ø§Ù„Ø¯Ù†ÛŒØ§ Ù…ØµÙˆÙ†\n",
            "0 : Ø®ÙˆØ´Ø§ Ø¯Ù„ÛŒ Ú©Ù‡ Ù…Ø¯Ø§Ù… Ø§Ø² Ù¾ÛŒ Ù†Ø¸Ø± Ù†Ø±ÙˆØ¯\n",
            "1 : Ø³Ø¹Ø¯ÛŒØ§ Ú¯ÙˆØ´Ù‡ Ù†Ø´ÛŒÙ†ÛŒ Ú©Ù† Ùˆ Ø´Ø§Ù‡Ø¯Ø¨Ø§Ø²ÛŒ\n",
            "2 : Ù‡ÙˆØ´Ù… Ù†Ù…Ø§Ù†Ø¯ Ùˆ Ø¹Ù‚Ù„ Ø¨Ø±ÙØª Ùˆ Ø³Ø®Ù† Ø¨Ø¨Ø³Øª\n",
            "3 : Ø¹Ù‡Ø¯ Ø¨Ø§ Ù¾ÛŒÙ…Ø§Ù†Ù‡ Ø¨Ù†Ø¯Ù… Ø´Ø±Ø· Ø¨Ø§ Ø³Ø§ØºØ± Ú©Ù†Ù…\n",
            "4 : Ù„ÛŒÚ©Ù† Ø¨Ø± Ø§Ø¨Ø±ÙˆØ§Ù†Ø´ Ø³Ø­Ø± Ù…Ø¨ÛŒÙ† Ù†Ø¨Ø§Ø´Ø¯\n",
            "5 : ÙˆØ§Ù„Ù‡ Ø´ÙˆØ¯ Ú©Ø¨Ú© Ø¯Ø±ÛŒ Ø·Ø§ÙˆÙˆØ³ Ø´Ù‡Ù¾Ø± Ø¨Ø±Ú©Ù†Ø¯\n",
            "6 : Ø¢Ø³Ù…Ø§Ù† Ø¨Ø§Ø± Ø§Ù…Ø§Ù†Øª Ù†ØªÙˆØ§Ù†Ø³Øª Ú©Ø´ÛŒØ¯\n",
            "7 : ÙˆØ± Ø®ÙˆØ¯ Ø§Ø² ØªØ®Ù…Ù‡ Ø¬Ù…Ø´ÛŒØ¯ Ùˆ ÙØ±ÛŒØ¯ÙˆÙ† Ø¨Ø§Ø´ÛŒ\n",
            "8 : Ø§ÛŒ Ø¹Ø²ÛŒØ² Ù…Ù† Ù†Ù‡ Ø¹ÛŒØ¨ Ø¢Ù† Ø¨Ù‡ Ú©Ù‡ Ù¾Ù†Ù‡Ø§Ù†ÛŒ Ø¨ÙˆØ¯\n",
            "9 : Ùˆ Ø¹Ù„Ù… Ø§Ù„Ù„Ù‡ Ø­Ø³Ø¨ÛŒ Ù…Ù† Ø³Ø¤Ø§Ù„ÛŒ\n",
            "\n",
            " Ù…ØµØ±Ø¹ Ø§ØµÙ„ÛŒ Ø´Ù…Ø§Ø±Ù‡ 15:â€Œ Ú©Ù…Ø«Ù„ Ø§Ù„Ø¨Ø¯Ø± ÙÛŒ Ø­Ø¯ Ø§Ù„Ú©Ù…Ø§Ù„\n",
            "0 : Ø­ÛŒÙ Ø§Ø³Øª Ø¨Ù„Ø¨Ù„ÛŒ Ú†Ùˆ Ù…Ù† Ø§Ú©Ù†ÙˆÙ† Ø¯Ø± Ø§ÛŒÙ† Ù‚ÙØ³\n",
            "1 : Ù‡ÙˆØ´Ù… Ù†Ù…Ø§Ù†Ø¯ Ùˆ Ø¹Ù‚Ù„ Ø¨Ø±ÙØª Ùˆ Ø³Ø®Ù† Ø¨Ø¨Ø³Øª\n",
            "2 : Ø§ÛŒÙ† Ø±Ø§ Ø´Ú©ÛŒØ¨ Ù†ÛŒØ³Øª Ú¯Ø± Ø¢Ù† Ø±Ø§ Ù…Ù„Ø§Ù„ØªØ³Øª\n",
            "3 : Ø² Ú†Ù…Ù† Ù†Ø±Ø³Øª Ø³Ø±ÙˆÛŒ Ú©Ù‡ Ø² Ø¨ÛŒØ® Ø¨Ø±Ù†Ú©Ù†Ø¯Ø´\n",
            "4 : Ú©Ø¬Ø§ Ø±ÙˆÙ… Ú©Ù‡ Ù†Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯Ù… Ú¯Ø²ÛŒØ± Ø§Ø² Ø¯ÙˆØ³Øª\n",
            "5 : Ø®ÙˆØ±Ø´ÛŒØ¯ Ú†Ùˆ Ø¢Ù† Ø®Ø§Ù„ Ø³ÛŒÙ‡ Ø¯ÛŒØ¯ Ø¨Ù‡ Ø¯Ù„ Ú¯ÙØª\n",
            "6 : Ù¾Ø§Ø¯Ø´Ø§Ù‡Ø§Ù† Ø¨Ù‡ ØºÙ„Ø· ÛŒØ§Ø¯ Ú¯Ø¯Ø§ Ù†ÛŒØ² Ú©Ù†Ù†Ø¯\n",
            "7 : Ù‡Ø²Ø§Ø± Ø¯Ø´Ù…Ù† Ø§Ú¯Ø± Ø¯Ø± Ù‚ÙØ§Ø³Øª Ø¹Ø§Ø±Ù Ø±Ø§\n",
            "8 : Ø§ÛŒ Ø¹Ø²ÛŒØ² Ù…Ù† Ù†Ù‡ Ø¹ÛŒØ¨ Ø¢Ù† Ø¨Ù‡ Ú©Ù‡ Ù¾Ù†Ù‡Ø§Ù†ÛŒ Ø¨ÙˆØ¯\n",
            "9 : Ú¯Ù„Ù‡ Ø§Ø² Ø¯Ø³Øª Ø¨ÙˆØ³ØªØ§Ù†Ø¨Ø§Ù†Øª\n",
            "\n",
            " Ù…ØµØ±Ø¹ Ø§ØµÙ„ÛŒ Ø´Ù…Ø§Ø±Ù‡ 16:â€Œ Ù…Ø±Ú©Ø¨ Ø¯Ø± ÙˆØ¬ÙˆØ¯Ù… Ù‡Ù…Ú†Ùˆ Ø¬Ø§Ù†ÛŒ\n",
            "0 : Ù‡Ù…Ú†Ù†Ø§Ù† Ø¹Ø§Ø´Ù‚ Ù†Ø¨Ø§Ø´Ø¯ ÙˆØ± Ø¨ÙˆØ¯ ØµØ§Ø¯Ù‚ Ù†Ø¨Ø§Ø´Ø¯\n",
            "1 : Ø¨Ù‡ Ø¯Ø±Ø¯ Ùˆ ØµØ§Ù ØªÙˆ Ø±Ø§ Ø­Ú©Ù… Ù†ÛŒØ³Øª Ø®ÙˆØ´ Ø¯Ø±Ú©Ø´\n",
            "2 : Ø·Ø§Ù‚Øª Ø¨Ø§Ø± Ø³ØªÙ… ØªØ§ Ú©ÛŒ Ùˆ Ù‡Ø¬Ø±Ø§Ù† ØªØ§ Ú†Ù†Ø¯\n",
            "3 : Ú†Ù…Ù† Ø­Ú©Ø§ÛŒØª Ø§Ø±Ø¯ÛŒØ¨Ù‡Ø´Øª Ù…ÛŒâ€ŒÚ¯ÙˆÛŒØ¯\n",
            "4 : Ø¢Ø³ØªÛŒÙ† Ø§Ø² Ú†Ù†Ú¯ Ù…Ø³Ú©ÛŒÙ†Ø§Ù† Ú¯Ø±ÙØªÙ… Ø¯Ø±Ú©Ø´Ø¯\n",
            "5 : ÙØ¯Ø§ÛŒ Ø®Ø§Ú© Ø¯Ø± Ø¯ÙˆØ³Øª Ø¨Ø§Ø¯ Ø¬Ø§Ù† Ú¯Ø±Ø§Ù…ÛŒ\n",
            "6 : Ø§ÛŒÙ† Ø¬Ø§Ù† Ø¹Ø§Ø±ÛŒØª Ú©Ù‡ Ø¨Ù‡ Ø­Ø§ÙØ¸ Ø³Ù¾Ø±Ø¯ Ø¯ÙˆØ³Øª\n",
            "7 : Ø¯Ø³Øª Ù…Ù† Ú¯ÛŒØ± Ú©Ù‡ Ø¨ÛŒÚ†Ø§Ø±Ú¯ÛŒ Ø§Ø² Ø­Ø¯ Ø¨Ú¯Ø°Ø´Øª\n",
            "8 : Ú©Ù‡ Ø¯Ø³Øª Ù‚Ø¯Ø±Øª Ú©ÙˆØªØ§Ù‡ Ù…Ø§ Ø¨Ø± Ø§Ùˆ ÛŒØ§Ø²Ø¯\n",
            "9 : Ù†Ø¯ÛŒØ¯Ù‡â€ŒØ§Ù†Ø¯ Ù…Ú¯Ø± Ø¯Ù„Ø¨Ø±Ø§Ù† Ø¨Øª Ø±Ùˆ Ø±Ø§\n",
            "\n",
            " Ù…ØµØ±Ø¹ Ø§ØµÙ„ÛŒ Ø´Ù…Ø§Ø±Ù‡ 17:â€Œ Ù…ØµÙˆØ± Ø¯Ø± Ø¯Ù…Ø§ØºÙ… Ú†ÙˆÙ† Ø®ÛŒØ§Ù„ÛŒ\n",
            "0 : Ú©ÛŒØ³Øª Ø¢Ù† Ú©Ø´ Ø³Ø± Ù¾ÛŒÙˆÙ†Ø¯ ØªÙˆ Ø¯Ø± Ø®Ø§Ø·Ø± Ù†ÛŒØ³Øª\n",
            "1 : Ø¨Ø± Ù…Ù† Ú©Ù‡ ØµØ¨ÙˆØ­ÛŒ Ø²Ø¯Ù‡â€ŒØ§Ù… Ø®Ø±Ù‚Ù‡ Ø­Ø±Ø§Ù…Ø³Øª\n",
            "2 : Ø¯ÛŒ Ù…ÛŒâ€ŒØ´Ø¯ Ùˆ Ú¯ÙØªÙ… ØµÙ†Ù…Ø§ Ø¹Ù‡Ø¯ Ø¨Ù‡ Ø¬Ø§ÛŒ Ø¢Ø±\n",
            "3 : Ø´Ù‡Ø± Ø®Ø§Ù„ÛŒØ³Øª Ø² Ø¹Ø´Ø§Ù‚ Ø¨ÙˆØ¯ Ú©Ø² Ø·Ø±ÙÛŒ\n",
            "4 : Ú©Ø¢Ø®Ø± Ù†Ø¯Ø§Ù†Ø¯ Ø¨ÛŒØ´ Ø§Ø² Ø§ÛŒÙ† ÛŒØ§ Ù…ÛŒâ€ŒÚ©Ø´Ø¯ ÛŒØ§ Ù…ÛŒâ€ŒØ¨Ø±Ø¯\n",
            "5 : Ú©Ù„Ú© Ø­Ø§ÙØ¸ Ø´Ú©Ø±ÛŒÙ† Ù…ÛŒÙˆÙ‡ Ù†Ø¨Ø§ØªÛŒØ³Øª Ø¨Ù‡ Ú†ÛŒÙ†\n",
            "6 : Ø´Ú© Ù†ÛŒØ³Øª Ú©Ù‡ Ø¨ÙˆØ³ØªØ§Ù† Ø¨Ø®Ù†Ø¯Ø¯\n",
            "7 : Ú¯Ø± Ù¾Ø³ Ø§Ø² Ø§ÛŒÙ† Ø¯Ù…ÛŒ Ú†Ù†Ø§Ù† ÛŒØ§Ø¨Ù… Ù‚Ø¯Ø± Ø¯Ø§Ù†Ù…Ø´\n",
            "8 : Ø¨Ù‡ Ø¯Ø± ØµÙˆÙ…Ø¹Ù‡ Ø¨Ø§ Ø¨Ø±Ø¨Ø· Ùˆ Ù¾ÛŒÙ…Ø§Ù†Ù‡ Ø±ÙˆÙ…\n",
            "9 : Ø§ÛŒ Ù†Ø³ÛŒÙ… ØµØ¨Ø­ Ø§Ú¯Ø± Ø¨Ø§Ø² Ø§ØªÙØ§Ù‚ÛŒ Ø§ÙØªØ¯Øª\n",
            "\n",
            " Ù…ØµØ±Ø¹ Ø§ØµÙ„ÛŒ Ø´Ù…Ø§Ø±Ù‡ 18:â€Œ ÙÙ…Ø§ Ø°Ø§Ù„Ù†ÙˆÙ… Ù‚ÛŒÙ„ Ø§Ù„Ù†ÙˆÙ… Ø±Ø§Ø­Ù‡\n",
            "0 : Ø¢Ù† Ú©Ù‡ Ù…Ù†Ø¸ÙˆØ± Ø¯ÛŒØ¯Ù‡ Ùˆ Ø¯Ù„ Ù…Ø§Ø³Øª\n",
            "1 : Ú©Ø¬Ø§ Ø±ÙˆÙ… Ú©Ù‡ Ù†Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯Ù… Ú¯Ø²ÛŒØ± Ø§Ø² Ø¯ÙˆØ³Øª\n",
            "2 : Ø­ÛŒÙ Ø§Ø³Øª Ø¨Ù„Ø¨Ù„ÛŒ Ú†Ùˆ Ù…Ù† Ø§Ú©Ù†ÙˆÙ† Ø¯Ø± Ø§ÛŒÙ† Ù‚ÙØ³\n",
            "3 : Ù…Ù† Ø¢Ù† Ø´Ú©Ù„ ØµÙ†ÙˆØ¨Ø± Ø±Ø§ Ø² Ø¨Ø§Øº Ø¯ÛŒØ¯Ù‡ Ø¨Ø±Ú©Ù†Ø¯Ù…\n",
            "4 : Ù‡Ø²Ø§Ø± Ø¯Ø´Ù…Ù† Ø§Ú¯Ø± Ø¯Ø± Ù‚ÙØ§Ø³Øª Ø¹Ø§Ø±Ù Ø±Ø§\n",
            "5 : Ú©Ø¬Ø§ ÛŒØ§Ø¨Ù… ÙˆØµØ§Ù„ Ú†ÙˆÙ† ØªÙˆ Ø´Ø§Ù‡ÛŒ\n",
            "6 : Ø¬ÙˆØ§Ù† Ø¨Ø®Øª Ø¬Ù‡Ø§Ù†Ù… Ú¯Ø± Ú†Ù‡ Ù¾ÛŒØ±Ù…\n",
            "7 : Ú©Ù‡ ÛŒÚ© Ú©Ø±Ø´Ù…Ù‡ ØªÙ„Ø§ÙÛŒ ØµØ¯ Ø¬ÙØ§ Ø¨Ú©Ù†Ø¯\n",
            "8 : Ø¢Ø¯Ù…ÛŒ Ù†ÛŒØ³Øª Ù…Ú¯Ø± Ú©Ø§Ù„Ø¨Ø¯ÛŒ Ø¨ÛŒâ€ŒØ¬Ø§Ù†Ø³Øª\n",
            "9 : Ø² Ú†Ù…Ù† Ù†Ø±Ø³Øª Ø³Ø±ÙˆÛŒ Ú©Ù‡ Ø² Ø¨ÛŒØ® Ø¨Ø±Ù†Ú©Ù†Ø¯Ø´\n",
            "\n",
            " Ù…ØµØ±Ø¹ Ø§ØµÙ„ÛŒ Ø´Ù…Ø§Ø±Ù‡ 19:â€Œ Ùˆ Ù…Ø§Ù„ÛŒ Ø§Ù„Ù†ÙˆÙ… ÙÛŒ Ø·ÙˆÙ„ Ø§Ù„Ù„ÛŒØ§Ù„ÛŒ\n",
            "0 : Ù‡ÙˆØ´Ù… Ù†Ù…Ø§Ù†Ø¯ Ùˆ Ø¹Ù‚Ù„ Ø¨Ø±ÙØª Ùˆ Ø³Ø®Ù† Ø¨Ø¨Ø³Øª\n",
            "1 : Ú©Ø¬Ø§ Ø±ÙˆÙ… Ú©Ù‡ Ù†Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯Ù… Ú¯Ø²ÛŒØ± Ø§Ø² Ø¯ÙˆØ³Øª\n",
            "2 : Ø² Ú†Ù…Ù† Ù†Ø±Ø³Øª Ø³Ø±ÙˆÛŒ Ú©Ù‡ Ø² Ø¨ÛŒØ® Ø¨Ø±Ù†Ú©Ù†Ø¯Ø´\n",
            "3 : Ø­ÛŒÙ Ø§Ø³Øª Ø¨Ù„Ø¨Ù„ÛŒ Ú†Ùˆ Ù…Ù† Ø§Ú©Ù†ÙˆÙ† Ø¯Ø± Ø§ÛŒÙ† Ù‚ÙØ³\n",
            "4 : Ø§ÛŒÙ† Ø±Ø§ Ø´Ú©ÛŒØ¨ Ù†ÛŒØ³Øª Ú¯Ø± Ø¢Ù† Ø±Ø§ Ù…Ù„Ø§Ù„ØªØ³Øª\n",
            "5 : Ù‡Ø²Ø§Ø± Ø¯Ø´Ù…Ù† Ø§Ú¯Ø± Ø¯Ø± Ù‚ÙØ§Ø³Øª Ø¹Ø§Ø±Ù Ø±Ø§\n",
            "6 : Ú©Ø¬Ø§ ÛŒØ§Ø¨Ù… ÙˆØµØ§Ù„ Ú†ÙˆÙ† ØªÙˆ Ø´Ø§Ù‡ÛŒ\n",
            "7 : Ø®ÙˆØ±Ø´ÛŒØ¯ Ú†Ùˆ Ø¢Ù† Ø®Ø§Ù„ Ø³ÛŒÙ‡ Ø¯ÛŒØ¯ Ø¨Ù‡ Ø¯Ù„ Ú¯ÙØª\n",
            "8 : Ø§ÛŒ Ø¹Ø²ÛŒØ² Ù…Ù† Ù†Ù‡ Ø¹ÛŒØ¨ Ø¢Ù† Ø¨Ù‡ Ú©Ù‡ Ù¾Ù†Ù‡Ø§Ù†ÛŒ Ø¨ÙˆØ¯\n",
            "9 : Ú¯Ù„Ù‡ Ø§Ø² Ø¯Ø³Øª Ø¨ÙˆØ³ØªØ§Ù†Ø¨Ø§Ù†Øª\n",
            "\n",
            " Ù…ØµØ±Ø¹ Ø§ØµÙ„ÛŒ Ø´Ù…Ø§Ø±Ù‡ 20:â€Œ Ø¯Ù…ÛŒ Ø¯Ù„Ø¯Ø§Ø±ÛŒ Ùˆ ØµØ§Ø­Ø¨ Ø¯Ù„ÛŒ Ú©Ù†\n",
            "0 : Ø¯Ù„ Ø§Ø² Ú©Ø±Ø´Ù…Ù‡ Ø³Ø§Ù‚ÛŒ Ø¨Ù‡ Ø´Ú©Ø± Ø¨ÙˆØ¯ ÙˆÙ„ÛŒ\n",
            "1 : Ø§Ø² Ø¹Ø¸Ù…Øª Ù…Ø§ÙˆØ±Ø§ÛŒ ÙÚ©Ø±Øª Ø¯Ø§Ù†Ø§\n",
            "2 : Ú†Ù‡ Ø´ÙˆØ¯ Ú¯Ø± Ù…Ù† Ùˆ ØªÙˆ Ú†Ù†Ø¯ Ù‚Ø¯Ø­ Ø¨Ø§Ø¯Ù‡ Ø®ÙˆØ±ÛŒÙ…\n",
            "3 : Ú¯Ø± Ø¢Ø³ØªÛŒÙ† Ø¯ÙˆØ³Øª Ø¨ÛŒÙØªØ¯ Ø¨Ù‡ Ø¯Ø³Øª Ù…Ù†\n",
            "4 : Ù…Ø§ Ù…Ø±Ø¯ Ø²Ù‡Ø¯ Ùˆ ØªÙˆØ¨Ù‡ Ùˆ Ø·Ø§Ù…Ø§Øª Ù†ÛŒØ³ØªÛŒÙ…\n",
            "5 : Ø¨Ù‡ Ø³Ø± Ø±Ø³ÛŒØ¯ Ø§Ù…ÛŒØ¯ Ùˆ Ø·Ù„Ø¨ Ø¨Ù‡ Ø³Ø± Ù†Ø±Ø³ÛŒØ¯\n",
            "6 : Ø¨Ú¯Ø°Ø±ÛŒ Ø§ÛŒ Ù¾ÛŒÚ© Ù†Ø³ÛŒÙ… ØµØ¨Ø§\n",
            "7 : ÛŒØ§Ø± Ø¨Ø§ ÛŒØ§Ø± Ø³ÙØ±Ú©Ø±Ø¯Ù‡ Ø¨Ù‡ ØªÙ†Ù‡Ø§ Ù†Ø±ÙˆØ¯\n",
            "8 : Ø³Ø¹Ø¯ÛŒ Ù…Ø¨Ø± Ø§Ù†Ø¯ÛŒØ´Ù‡ Ú©Ù‡ Ø¯Ø± Ú©Ø§Ù… Ù†Ù‡Ù†Ú¯Ø§Ù†\n",
            "9 : Ù…Ù† Ø§Ø² ØªÙˆ Ù¾ÛŒØ´ Ú©Ù‡ Ù†Ø§Ù„Ù… Ú©Ù‡ Ø¯Ø± Ø´Ø±ÛŒØ¹Øª Ø¹Ø´Ù‚\n",
            "\n",
            " Ù…ØµØ±Ø¹ Ø§ØµÙ„ÛŒ Ø´Ù…Ø§Ø±Ù‡ 21:â€Œ Ú©Ù‡ Ø¨Ø±Ø®ÙˆØ± Ø¨Ø§Ø¯ÛŒ Ø§Ø² ØµØ§Ø­Ø¨ Ø¬Ù…Ø§Ù„ÛŒ\n",
            "0 : Ù…Ø±Ø§ ÙØªØ§Ø¯ Ø¯Ù„ Ø§Ø² Ø±Ù‡ ØªÙˆ Ø±Ø§ Ú†Ù‡ Ø§ÙØªØ§Ø¯Ø³Øª\n",
            "1 : Ø¨Ù†Ø¯Ù‡ Ø®ÙˆÛŒØ´ØªÙ†Ù… Ø®ÙˆØ§Ù† Ú©Ù‡ Ø¨Ù‡ Ø´Ø§Ù‡ÛŒ Ø¨Ø±Ø³Ù…\n",
            "2 : ØªÙˆ Ú¯Ø± ØªØ±Ø´ Ø¨Ù†Ø´ÛŒÙ†ÛŒ Ù‚Ø¶Ø§ Ú†Ù‡ ØºÙ… Ø¯Ø§Ø±Ø¯\n",
            "3 : Ø¨Ø¹Ø¯ Ø§Ø² Ø¢Ù† Ù†Ø§Ù…Øª Ø¨Ù‡ Ø±Ø³ÙˆØ§ÛŒÛŒ Ø¨Ø±Ø¢ÛŒØ¯ Ù†Ù†Ú¯ Ù†ÛŒØ³Øª\n",
            "4 : ÙØ±Ø§ØºØª Ø¨Ø§Ø´Ø¯ Ø§Ø² Ø´Ø§Ù‡ Ùˆ ÙˆØ²ÛŒØ±Ù…\n",
            "5 : Ø´Ú©Ø³ØªÙ‡ ÙˆØ§Ø± Ø¨Ù‡ Ø¯Ø±Ú¯Ø§Ù‡Øª Ø¢Ù…Ø¯Ù… Ú©Ù‡ Ø·Ø¨ÛŒØ¨\n",
            "6 : Ú¯ÙˆÛŒÛŒ Ú©Ù‡ Ù†ÛŒØ´ÛŒ Ø¯ÙˆØ± Ø§Ø² Ø§Ùˆ Ø¯Ø± Ø§Ø³ØªØ®ÙˆØ§Ù†Ù… Ù…ÛŒâ€ŒØ±ÙˆØ¯\n",
            "7 : ÙˆÛŒÙ† Ù…Ø§Ø¬Ø±Ø§ Ø¨Ù‡ Ø³Ø±Ùˆ Ù„Ø¨ Ø¬ÙˆÛŒØ¨Ø§Ø± Ø¨Ø®Ø´\n",
            "8 : Ù†Ù…ÛŒâ€ŒØ¨Ø§ÛŒØ¯ Ú©Ù‡ ÙˆØ§Ù…Ù‚ Ø±Ø§ Ø´Ú©Ø§ÛŒØª Ø¨Ø± Ø²Ø¨Ø§Ù† Ø¢ÛŒØ¯\n",
            "9 : Ú©Ù‡ Ø­Ú©Ù… Ø¨Ø± Ø³Ø± Ø¢Ø²Ø§Ø¯Ú¯Ø§Ù† Ø±ÙˆØ§Ù† Ø¯Ø§Ø±ÛŒ\n",
            "\n",
            " Ù…ØµØ±Ø¹ Ø§ØµÙ„ÛŒ Ø´Ù…Ø§Ø±Ù‡ 22:â€Œ Ø§Ù„Ù… ØªÙ†Ø¸Ø± Ø§Ù„ÛŒ Ø¹ÛŒÙ†ÛŒ Ùˆ Ø¯Ù…Ø¹ÛŒ\n",
            "0 : Ø±ÙˆÛŒ ØªØ§Ø¬ÛŒÚ©Ø§Ù†Ù‡â€ŒØ§Øª Ø¨Ù†Ù…Ø§ÛŒ ØªØ§ Ø¯Ø§Øº Ø­Ø¨Ø´\n",
            "1 : Ú¯Ù„Ù‡ Ø§Ø² Ø¯Ø³Øª Ø¨ÙˆØ³ØªØ§Ù†Ø¨Ø§Ù†Øª\n",
            "2 : Ú©Ù‡ Ø¨Ø¯ÛŒÙ† Ø±Ø§Ù‡ Ø¨Ø´Ø¯ ÛŒØ§Ø± Ùˆ Ø² Ù…Ø§ ÛŒØ§Ø¯ Ù†Ú©Ø±Ø¯\n",
            "3 : Ù‡ÛŒÚ† Ú©Ø³ Ù†ÛŒØ³Øª Ú©Ù‡ Ù…Ø·Ù„ÙˆØ¨ Ù…Ø±Ø§ Ø¬ÙˆÛŒØ§Ù† Ù†ÛŒØ³Øª\n",
            "4 : Ø² Ù¾Ø±Ø¯Ù‡ Ú©Ø§Ø´ Ø¨Ø±ÙˆÙ† Ø¢Ù…Ø¯ÛŒ Ú†Ùˆ Ù‚Ø·Ø±Ù‡ Ø§Ø´Ú©\n",
            "5 : Ø§Ú¯Ø± Ú†Ù‡ Ø®Ø±Ù…Ù† Ø¹Ù…Ø±Ù… ØºÙ… ØªÙˆ Ø¯Ø§Ø¯ Ø¨Ù‡ Ø¨Ø§Ø¯\n",
            "6 : Ú©Ø¬Ø§ ÛŒØ§Ø¨Ù… ÙˆØµØ§Ù„ Ú†ÙˆÙ† ØªÙˆ Ø´Ø§Ù‡ÛŒ\n",
            "7 : Ú©Ø² Ø¯Ø³Øª Ù†ÛŒÚ©ÙˆØ§Ù† Ù‡Ù…Ù‡ Ú†ÛŒØ²ÛŒ Ù†Ú©Ùˆ Ø¨ÙˆØ¯\n",
            "8 : ØªÙˆ Ø¨ÙØ±Ù…Ø§ Ú©Ù‡ Ù…Ù† Ø³ÙˆØ®ØªÙ‡ Ø®Ø±Ù…Ù† Ú†Ù‡ Ú©Ù†Ù…\n",
            "9 : Ù¾Ø§Ø¯Ø´Ø§Ù‡Ø§Ù† Ø¨Ù‡ ØºÙ„Ø· ÛŒØ§Ø¯ Ú¯Ø¯Ø§ Ù†ÛŒØ² Ú©Ù†Ù†Ø¯\n",
            "\n",
            " Ù…ØµØ±Ø¹ Ø§ØµÙ„ÛŒ Ø´Ù…Ø§Ø±Ù‡ 23:â€Œ ØªØ±ÛŒ ÙÛŒ Ø§Ù„Ø¨Ø­Ø± Ø§ØµØ¯Ø§Ù Ø§Ù„Ù„Ø§Ù„ÛŒ\n",
            "0 : Ù†Ø¸Ù… Ù‡Ø± Ú¯ÙˆÙ‡Ø± Ù†Ø§Ø³ÙØªÙ‡ Ú©Ù‡ Ø­Ø§ÙØ¸ Ø±Ø§ Ø¨ÙˆØ¯\n",
            "1 : Ø®ÙˆØ±Ø´ÛŒØ¯ Ú†Ùˆ Ø¢Ù† Ø®Ø§Ù„ Ø³ÛŒÙ‡ Ø¯ÛŒØ¯ Ø¨Ù‡ Ø¯Ù„ Ú¯ÙØª\n",
            "2 : Ú©Ù‡ ÛŒÚ© Ú©Ø±Ø´Ù…Ù‡ ØªÙ„Ø§ÙÛŒ ØµØ¯ Ø¬ÙØ§ Ø¨Ú©Ù†Ø¯\n",
            "3 : Ø±ÙˆÛŒ ØªØ§Ø¬ÛŒÚ©Ø§Ù†Ù‡â€ŒØ§Øª Ø¨Ù†Ù…Ø§ÛŒ ØªØ§ Ø¯Ø§Øº Ø­Ø¨Ø´\n",
            "4 : Ù¾Ø§Ø¯Ø´Ø§Ù‡Ø§Ù† Ø¨Ù‡ ØºÙ„Ø· ÛŒØ§Ø¯ Ú¯Ø¯Ø§ Ù†ÛŒØ² Ú©Ù†Ù†Ø¯\n",
            "5 : Ù‡Ø²Ø§Ø± Ø¯Ø´Ù…Ù† Ø§Ú¯Ø± Ø¯Ø± Ù‚ÙØ§Ø³Øª Ø¹Ø§Ø±Ù Ø±Ø§\n",
            "6 : Ù‡ÛŒÚ† Ú©Ø³ Ù†ÛŒØ³Øª Ú©Ù‡ Ù…Ø·Ù„ÙˆØ¨ Ù…Ø±Ø§ Ø¬ÙˆÛŒØ§Ù† Ù†ÛŒØ³Øª\n",
            "7 : Ù‡Ø±Ú¯Ø² Ø¨Ù‡ Ø¹Ù…Ø± Ø±ÙˆØ²ÛŒ Ø±ÙˆØ²ÛŒ Ø´ÙˆØ¯ ÙˆØµØ§Ù„ÛŒ\n",
            "8 : ØªÙˆ Ø¨ÙØ±Ù…Ø§ Ú©Ù‡ Ù…Ù† Ø³ÙˆØ®ØªÙ‡ Ø®Ø±Ù…Ù† Ú†Ù‡ Ú©Ù†Ù…\n",
            "9 : Ù¾Ø³ Ø²Ø§Ù‡Ø¯Ø§Ù† Ø¨Ø±Ø§ÛŒ Ú†Ù‡ Ø®Ù„ÙˆØª Ú¯Ø²ÛŒØ¯Ù‡â€ŒØ§Ù†Ø¯\n",
            "\n",
            " Ù…ØµØ±Ø¹ Ø§ØµÙ„ÛŒ Ø´Ù…Ø§Ø±Ù‡ 24:â€Œ Ø¨Ù‡ Ú¯ÙˆØ´Øª Ú¯Ø± Ø±Ø³Ø§Ù†Ù… Ù†Ø§Ù„Ù‡ Ø²Ø§Ø±\n",
            "0 : Ø¹ÛŒØ´Ø³Øª Ø¨Ø± Ú©Ù†Ø§Ø± Ø³Ù…Ù† Ø²Ø§Ø± Ø®ÙˆØ§Ø¨ ØµØ¨Ø­\n",
            "1 : ÙØ¶Ù„Ø³Øª Ø§Ú¯Ø±Ù… Ø®ÙˆØ§Ù†ÛŒ Ø¹Ø¯Ù„Ø³Øª Ø§Ú¯Ø±Ù… Ø±Ø§Ù†ÛŒ\n",
            "2 : ÙˆØ² Ø¯ÛŒØ¯Ù‡ Ø¯Ù„ Ù†Ù…ÛŒâ€ŒØ´ÙˆÛŒ Ø¯ÙˆØ±\n",
            "3 : ÙˆØ² Ù‚Ø¯ Ø¨Ù„Ù†Ø¯ Ø§Ùˆ Ø¨Ø§Ù„Ø§ÛŒ ØµÙ†ÙˆØ¨Ø± Ù¾Ø³Øª\n",
            "4 : Ø±Ù‡Ø²Ù† Ø¯Ù‡Ø± Ù†Ø®ÙØªÙ‡â€ŒØ³Øª Ù…Ø´Ùˆ Ø§ÛŒÙ…Ù† Ø§Ø² Ø§Ùˆ\n",
            "5 : Ø¯ÙˆÙ„Øª Ø¯Ø± Ø¢Ù† Ø³Ø±Ø§ Ùˆ Ú¯Ø´Ø§ÛŒØ´ Ø¯Ø± Ø¢Ù† Ø¯Ø± Ø§Ø³Øª\n",
            "6 : Ú©Ù‡ Ú†Ø´Ù… Ø³Ø¹ÛŒ Ø¶Ø¹ÛŒÙØ³Øª Ø¨ÛŒ Ú†Ø±Ø§Øº Ù‡Ø¯Ø§ÛŒØª\n",
            "7 : Ù†ÙˆØ¨Ù‡Ø§Ø± Ø§Ø³Øª Ø¯Ø± Ø¢Ù† Ú©ÙˆØ´ Ú©Ù‡ Ø®ÙˆØ´Ø¯Ù„ Ø¨Ø§Ø´ÛŒ\n",
            "8 : Ú©Ø² Ø¨Ø§Ø¯ Ø³Ø¨Ù‚ Ø¨Ø±Ø¯ Ø¹Ù†Ø§Ù†Øª\n",
            "9 : ØªØ§ Ù‡ÙˆØ§Ø®ÙˆØ§Ù‡ ØªÙˆ Ø´Ø¯ ÙØ± Ù‡Ù…Ø§ÛŒÛŒ Ø¯Ø§Ø±Ø¯\n"
          ]
        }
      ]
    }
  ]
}